<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>算法个人总结</title>
    <url>/2020/cklqjzoum0001ouq18oz179gq/</url>
    <content><![CDATA[<h1>Quick Sort</h1>
<h2 id="原理">原理</h2>
<p>使用了分治的思想</p>
<ol>
<li>选择A中的任意一个元素pivot，该元素作为基准</li>
<li>将小于基准的元素移到左边，大于基准的元素移到右边（分区操作）</li>
<li>A被pivot分为两部分，继续对剩下的两部分做同样的处理</li>
<li>直到所有子集元素不再需要进行上述步骤</li>
</ol>
<h2 id="如何找基准数">如何找基准数</h2>
<p>最坏情况：每次分完后两边是1和n-1，O(N^2)</p>
<ol>
<li>固定基准数</li>
<li>随机基准数</li>
<li>三数取中: 左端右端和中位数</li>
</ol>
<h2 id="java实现思路">java实现思路</h2>
<ol>
<li>选择一个基准数A</li>
<li>从左侧开始，找到一个比A大的数，交换</li>
<li>再从右侧开始，找到一个比A小的数，交换</li>
<li>重复2和3</li>
</ol>
<h1>Skip List(跳表)</h1>
<p><a href="https://redisbook.readthedocs.io/en/latest/internal-datastruct/skiplist.html">Reference</a></p>
<h1>大数据场景题</h1>
<h2 id="1亿数据取top10">1亿数据取top10</h2>
<p><a href="https://blog.csdn.net/zyq522376829/article/details/47686867">1亿数据取top10000</a><br>
先通过hash对数据去重</p>
<ol>
<li>将数据全部排序找</li>
<li>堆排序 最小堆</li>
<li>分治法：将1亿数据分为100份，每分100万个数据，找到每分中最大的1万个，之后对100*10000（即100w）找到最大的10000</li>
</ol>
<h2 id="有一个1g大小的一个文件-里面每一行是一个词-词的大小不超过16字节-内存限制大小是1m-返回频数最高的100个词">有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词</h2>
<ol>
<li>一共有2^16</li>
</ol>
<h2 id="1亿数据取出现频率top10">1亿数据取出现频率top10</h2>
<ol>
<li>将文件hash取模成多个小文件</li>
<li>重复URL一定落到同一个文件中，对每个文件进行统计即可，取出频率前10</li>
<li>之后将这些数据合起来再统计一次</li>
</ol>
<h2 id="1亿url取出重复url">1亿URL取出重复URL</h2>
<ol>
<li>将文件hash取模成多个小文件</li>
<li>重复URL一定落到同一个文件中，对每个文件进行统计即可</li>
</ol>
<h2 id="给定a-b两个文件-各存放50亿个url-每个url各占64字节-内存限制是4g-让你找出a-b文件共同的url">给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url</h2>
<ol>
<li>每个文件大小 5G*64=320G，内存放不下，需要切分文件</li>
<li>对每个url取hash值%1000，存储到1000个小文件中</li>
<li>对照(a0,b0),(a1,b1),…，因为相同的url一定会被分到对应的小文件中</li>
</ol>
<h2 id="在2-5亿个整数中找出不重复的整数">在2.5亿个整数中找出不重复的整数</h2>
<ol>
<li>分治法<br>
1.1. 划分为多个小文件，找出每个小文件中不重复的数字<br>
1.2. 归并剔除重复的数字<br>
1.3. 问题就是所有数字都不重复</li>
<li>Bitmap<br>
2.1. 采用2-Bitmap每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存 0.25G*2=0.5GB 内存<br>
2.2. 扫描Bitmap，如果是00则改为01，如果是01则改为10，如果是10则不变<br>
2.3. 最后输出bitmap为01的数</li>
</ol>
]]></content>
      <categories>
        <category>Interview</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Algorithm</tag>
        <tag>Big Data Scenario</tag>
      </tags>
  </entry>
  <entry>
    <title>Go个人学习</title>
    <url>/2021/cklqjzoup0003ouq13wjr1lw0/</url>
    <content><![CDATA[<p><a href="https://golang.org/ref/spec">Go Official Specification</a></p>
<p>主要记录一些小知识点</p>
<h1>Types</h1>
<ol>
<li>数字可以写成<code>100_000_000</code></li>
<li><code>uint</code> = either 32 or 64 bits, <code>int</code> = same size as uint, 所以<code>int32</code>和<code>int</code>不是同一个类型</li>
</ol>
<h1>Struct</h1>
<p>定义struct时，如果没有定义field name，那么field name和类型同名</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> &#123;</span><br><span class="line">	T1        <span class="comment">// field name is T1</span></span><br><span class="line">	*T2       <span class="comment">// field name is T2</span></span><br><span class="line">	P.T3      <span class="comment">// field name is T3</span></span><br><span class="line">	*P.T4     <span class="comment">// field name is T4</span></span><br><span class="line">	x, y <span class="keyword">int</span>  <span class="comment">// field names are x and y</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1>Channel</h1>
<p><code>make(chan int, 100)</code>: 不设置capacity，只有当sender和receiver ready之后才能使用；<br>
设置capacity相当于设置了buffer，在buffer不满(sends)或者buffer不空(receives)时，不会阻塞。</p>
<h1>Goroutine原理</h1>
<h2 id="mpg模型"><a href="https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/">MPG模型</a></h2>
<ol>
<li>M是machine，一个M直接关联了一个内核线程，由操作系统管理</li>
<li>P是Processor，代表了M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接</li>
<li>G是Goroutine</li>
</ol>
]]></content>
      <categories>
        <category>Self-Learning</category>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Self-Learning</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql面试个人总结</title>
    <url>/2020/cklqjzous0006ouq18dycafit/</url>
    <content><![CDATA[<h1>Engines</h1>
<p>InnoDB, MEMORY, MyISAM</p>
<h2 id="myisam-vs-innodb">MyISAM vs InnoDB</h2>
<p><a href="https://dba.stackexchange.com/questions/1/what-are-the-main-differences-between-innodb-and-myisam">Reference</a></p>
<table>
<thead>
<tr>
<th></th>
<th>min lock level</th>
<th>support transaction and crash recovery</th>
<th>support foreign key</th>
<th>support MVCC</th>
</tr>
</thead>
<tbody>
<tr>
<td>InnoDB</td>
<td>row-level</td>
<td>YES</td>
<td>YES</td>
<td>YES</td>
</tr>
<tr>
<td>MyISAM</td>
<td>table-level</td>
<td>NO</td>
<td>NO</td>
<td>NO</td>
</tr>
</tbody>
</table>
<p>在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构（主索引）。</p>
<h3 id="mvcc">MVCC</h3>
<ol>
<li>MVCC是一种并发控制的方法</li>
<li>MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作，因为 READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁。</li>
</ol>
<h1>Index</h1>
<p><a href="https://blog.codinglabs.org/articles/theory-of-mysql-index.html">这篇非常吊</a><br>
索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。<br>
相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。<br>
换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。</p>
<ol>
<li>B-Tree Index:
<ol>
<li>MyISAM: Data address(Not Data) is stored in B+Tree leaves data field, which is called  nonclustered index <br><br>
<img src="https://img-blog.csdn.net/20180421144534845?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xKRlBIUA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="Nonclustered Index"></li>
<li>InnoDB:<br>
<a href="https://www.xaprb.com/blog/2006/07/04/how-to-exploit-mysql-index-optimizations/">Reference1</a><br>
<a href="https://www.jianshu.com/p/c3fb0b01c44d">Reference2</a>
<ol>
<li>Clustered/Primary Index(聚集索引/主键索引)： leaves store primary keys and relevant row(数据页) <br><br>
<img src="https://img-blog.csdn.net/20180421144550724?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xKRlBIUA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="Clustered Index">
<ol>
<li>InnoDB creates a clustered index for every table.</li>
<li>If the table has a primary key, that is the clustered index.</li>
<li>If not, InnoDB internally assigns a six-byte unique ID to every row and uses that as the clustered index.</li>
</ol>
</li>
<li>secondary index(辅助索引)： leaves store primary keys(use primary key to find row later, which means it will search indexes twice) <br><br>
<img src="https://upload-images.jianshu.io/upload_images/1293895-eeb9baea003174f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/543/format/webp" alt="Secondary Index"></li>
<li>Hence, we don’t use big data structure for primary key since it will increase the size of secondary index</li>
<li>recommend to use auto-increase key as primary key(因为非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效)</li>
<li>节点大小为磁盘页的整数倍</li>
</ol>
</li>
</ol>
</li>
<li>Hash Index:</li>
<li>bitmap Index:</li>
<li>R-Tree Index<br>
<a href="https://dev.mysql.com/doc/refman/8.0/en/index-btree-hash.html">Comparison of B-Tree and Hash Indexes</a></li>
<li><a href="https://yq.aliyun.com/articles/62419">Covering Index</a>(覆盖索引): 指一个查询语句的执行只需要从辅助索引中就可以得到查询记录，而不需要查询聚集索引中的记录。也可以称之为实现了索引覆盖。<br>
即，一个索引包含或者说覆盖所有需要查询的字段的值</li>
<li>联合索引：KEY test_col1_col2_col3 on test(col1,col2,col3);实际上建立了(col1)、(col1,col2)、(col,col2,col3)三个索引</li>
<li>最左匹配（前缀）原则：（在生成的b树索引中，索引首先根据第一个字段来排列顺序，然后才是之后的字段）
<ol>
<li>where后的条件语句要满足(col1=??)、(col1=?? and col2=??)、(col1=?? and col2=?? and col3=?)</li>
<li>不可以是(col=?? and col3=?)，不能漏掉col2</li>
<li>顺序没关系(col2=?? and col1=?? and col3=?)是可以的，因为mysql的查询优化器会重新调整他们的位子</li>
</ol>
</li>
<li>如何选择索引顺序<br>
比较count(DISTINCT(column))/count(*)，选择大的那个</li>
<li>避免多个范围条件：因为mysql只会选择其中一个索引</li>
<li>索引的坏处：
<ol>
<li>索引文件本身要消耗存储空间</li>
<li>索引会加重插入、删除和修改记录时的负担</li>
<li>因此数据量少的表或者是count(DISTINCT(column))/count(*)小的表不建议建索引(data sparsity)</li>
</ol>
</li>
</ol>
<h2 id="根据where建立索引">根据Where建立索引</h2>
<p><a href="https://www.cnblogs.com/rjzheng/p/12557314.html">Reference</a></p>
<h2 id="为什么用b-树而不是红黑树或者其他数据结构">为什么用B+树而不是红黑树或者其他数据结构</h2>
<p>主要和磁盘读取存储有关，为了减少IO，磁盘不会按需读取，一般是磁盘预读（即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存）。<br>
预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，<br>
每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。</p>
<p>B树索引，每次新建节点时会直接申请一个页，实现了一个node一次IO读取。<br>
B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(log_d{N})。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。<br>
而红黑树这种结构，h明显要深的多，效率明显比B-Tree差很多。</p>
<h2 id="为什么用b-树而不是b树">为什么用B+树而不是B树</h2>
<ol>
<li>B+树可以实现区间访问，B树不行</li>
<li>B+树IO访问次数少，因为非叶子节点都是索引不是数据</li>
</ol>
<h2 id="为什么要使用一个与业务无关的自增字段作为主键">为什么要使用一个与业务无关的自增字段作为主键</h2>
<p>mysql的InnoDB引擎中使用的是B树，如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。<br>
非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据。<br>
业务有关的字段肯定是无序的，所以不能用来做主键。</p>
<h1>原子性和持久性的实现原理</h1>
<p><a href="https://www.cnblogs.com/rjzheng/p/10841031.html">原子性和一致性</a></p>
<ol>
<li>Mysql怎么保证原子性：利用Innodb的undo log</li>
<li>Mysql怎么保持持久性：利用Innodb的redo log</li>
</ol>
<h1>隔离级别</h1>
<p><img src="https://developer.ibm.com/zh/technologies/databases/articles/os-mysql-transaction-isolation-levels-and-locks/" alt="隔离级别"></p>
<table>
<thead>
<tr>
<th></th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>read uncommitted</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>read committed</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>read repeatable</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>serializable</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>mysql默认级别：read repeatable</p>
<h2 id="不可重复读和幻读">不可重复读和幻读</h2>
<p><a href="https://www.cnblogs.com/itcomputer/articles/5133254.html">Reference</a><br>
不可重复读重点在于update，而幻读的重点在于insert</p>
<ol>
<li>在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了</li>
<li>但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，<br>
这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免；serializable会串行执行指令，给读操作加一把读共享锁，在写的时候<br>
这个锁是锁住的，不能读，因此也消除了幻读</li>
</ol>
<h1>DBMS Architecture</h1>
<ol>
<li>All data are stored in data files, which is grouped in table space<br>
(file group: Logical grouping of several data files that store data with similar characteristics)</li>
<li>Data files(SQL )</li>
<li>Listener: listen for client request(SQL request), and then pass to User process</li>
<li>User: manage each client session</li>
<li>Scheduler: organize the concurrent execution of SQL requests</li>
<li>Lock Manager: manages all locks placed on database objects, including disk pages</li>
<li>Optimizer: analyze SQL queries and finds the most efficient way to access the data</li>
</ol>
<h2 id="query-processing">Query Processing</h2>
<ol>
<li>Parsing phase: use access plan(use the access plan if exist, if not optimizer will choose the best one)</li>
<li>Execution phase: all IO operations indicated in the access plan are executed
<ol>
<li>acquire the locks</li>
<li>retrieve data and place in data cache</li>
<li>process transaction management</li>
</ol>
</li>
<li>Fetching phase: return rows of resulting query result set</li>
</ol>
<h2 id="查询优化">查询优化</h2>
<p>There are two optimizer rule-based optimizer and cost-based optimizer.</p>
<ol>
<li>MySQL使用了基于成本的优化器，可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本</li>
<li>优化策略
<ol>
<li>重新定义表的关联顺序</li>
<li>优化MIN()和MAX()函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文）</li>
<li>提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）</li>
<li>优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）</li>
<li>etc</li>
</ol>
</li>
<li>优化器会生成执行计划</li>
<li>优化器提示(hint): <code>SELECT select_list FROM table_name USE INDEX(index_list) WHERE condition;</code><br>
<img src="https://ask.qcloudimg.com/http-save/yehe-1667832/qfvxpyxocc.jpeg?imageView2/2/w/1620" alt="查询过程"></li>
</ol>
<p><img src="https://pic4.zhimg.com/80/v2-43ccb9ca6d510bc5a7b7d023ff9bcf87_1440w.jpg" alt="查询过程"></p>
<h2 id="查询缓存">查询缓存</h2>
<p><a href="https://cloud.tencent.com/developer/article/1103154">Reference</a></p>
<ol>
<li>MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。</li>
<li>查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果都不会被缓存</li>
<li>MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。</li>
<li>任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存</li>
<li>通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存(可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会)</li>
</ol>
<h2 id="语法解析和预处理">语法解析和预处理</h2>
<p><a href="https://tech.meituan.com/2018/05/20/sql-parser-used-in-mtdp.html">SQL解析过程</a></p>
<ol>
<li>词法分析(MySQLLex): 将输入转化成一个个Token(e.g. <code>select username from user</code> -&gt; 4个token select, username, from和user)。具体代码在sql/lex.h和sql/sql_lex.cc文件中</li>
<li>语法分析：用于生成语法树，使用了Bison
<ol>
<li>e.g. <code>select username, ismale from userinfo where age &gt; 20 and level &gt; 5 and 1 = 1</code> 会生成如下语法树<br>
<img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018a/a74c9e9c.png" alt="语法树"></li>
</ol>
</li>
</ol>
<h1>Optimization</h1>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485117&amp;idx=1&amp;sn=92361755b7c3de488b415ec4c5f46d73&amp;chksm=cea24976f9d5c060babe50c3747616cce63df5d50947903a262704988143c2eeb4069ae45420&amp;token=79317275&amp;lang=zh_CN#rd">Reference</a></p>
<ol>
<li>通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用BIGINT存储。这样可以避免浮点数计算不准确和DECIMAL精确计算代价高的问题。</li>
<li>大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇技淫巧可以解决这个问题，有兴趣可自行查阅。</li>
<li>优化<code>select * from table where age &gt; 20 limit 1000000,10</code>: <code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10) </code><br>
子查询使用的索引是覆盖索引，不需要回表</li>
<li>在检索效率上来讲,char &gt; varchar</li>
</ol>
<h2 id="possible-reasons-if-sql-is-executed-slowly">Possible Reasons if SQL is executed slowly</h2>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485185&amp;idx=1&amp;sn=66ef08b4ab6af5757792223a83fc0d45&amp;chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&amp;token=79317275&amp;lang=zh_CN#rd">Reference</a></p>
<ol>
<li>Mysql is flushing dirty pages(When you update a row, MySQL updates it in the buffer pool, marking the page as dirty.)
<ol>
<li>When redo log is full</li>
<li>When memory is not enough</li>
<li>MYSQL think system is in low load and it is a suitable time to flush</li>
</ol>
</li>
<li>Encounter locks when executing</li>
<li>No index for query fields</li>
<li>MYSQL doesn’t use index properly when executing</li>
</ol>
<h1>Others</h1>
<ol>
<li>varchar(10)和int(10)各代表什么含义: varchar的10代表了申请的空间长度,也是可以存储的数据的最大长度,而int的10只是代表了展示的长度,不足10位以0填充.<br>
也就是说,int(1)和int(10)所能存储的数字大小以及占用的空间都是相同的,只是在展示时按照长度展示</li>
</ol>
<h2 id="olap-online-analytical-processing">OLAP(Online Analytical Processing)</h2>
<p><img src="http://bytes.usc.edu/cs585/s20_db0ds1ml2agi/lectures/BI/pics/s039.png" alt="OLAP"></p>
<h1><a href="https://my.oschina.net/MiniBu/blog/270521">SQL注入和预防</a></h1>
<p>e.g. 在程序中<code>String sql = &quot;select * from user_table where username= (userName) and password= (password);</code><br>
usrName传入<code>&quot;or 1 = 1 –</code>，得到<code>SELECT * FROM user_table WHERE username=&quot;or 1 = 1 -- and password='’</code><br>
<code>1=1</code>条件一定成功，<code>--</code>将后面的语句注视掉，甚至可以传入<code>drop database</code></p>
<p>预防：</p>
<ol>
<li>采用预编译语句集(PreparedStatement)：内置了处理SQL注入的能力<br>
因为 preparedStatement 中可以不包含数据，只包含操作，不需要用数据来拼接 SQL。<br>
编译过程识别了关键字、执行逻辑之类的东西，编译结束了这条SQL语句能干什么就定了。<br>
而在编译之后加入注入的部分，就已经没办法改变执行逻辑了，这部分就只能是相当于输入字符串被处理。</li>
<li>限制数据库权限</li>
<li>检查用户输入的合法性</li>
<li>对特殊字符’,&quot;进行转义</li>
</ol>
]]></content>
      <categories>
        <category>Interview</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Mysql</tag>
        <tag>Index</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Computer System Security(MIT 6.858)</title>
    <url>/2020/cklqjzouu0008ouq130cs5y9i/</url>
    <content><![CDATA[<h1>Buffer Overflow</h1>
<h2 id="buggy-c-code">buggy C code</h2>
<p>solution: don’t use C, because almost languages check buffer overflow except C.<br>
But this is not doable</p>
<h2 id="attack">Attack</h2>
]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Buffer Overflow</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux命令总结</title>
    <url>/2020/cklqjzouv0009ouq180f78qv3/</url>
    <content><![CDATA[<p><a href="https://readthedocs.org/projects/lym/downloads/pdf/latest/">Linux Command online PDF</a></p>
<h1>Main Directory in Linux</h1>
<h2 id="proc">/proc</h2>
<p>This is a virtual filesystem which contains information about all the<br>
running processes, and information about the hardware present in the system.<br>
Such as files: cpuinfo, cmdline, meminfo</p>
<h1>Compression</h1>
<h2 id="tar">tar</h2>
<ol>
<li><code>tar -xzvf files.tar.gz</code></li>
<li><code>tar -xjvf files.tar.bz2</code></li>
<li><code>tar -cjvf files.tar.gz hello.c bye.txt</code><br>
<code>x</code>: extract, <code>c</code>: create, <code>z</code>: gzip, <code>j</code>: bzip, <code>v</code>: verbose, <code>f</code>: file</li>
</ol>
<h1>environment variable</h1>
<ol>
<li><code>printenv</code></li>
<li><code>echo $PATH</code></li>
</ol>
<h1>Users and Groups</h1>
<p><code>cat /etc/passwd</code> (contains all the users available in the system)</p>
<h1>Processes</h1>
<ol>
<li><code>ps aux</code></li>
<li><code>top</code></li>
</ol>
<h1>Memory</h1>
<p><a href="https://www.tecmint.com/check-memory-usage-in-linux/">Free Reference</a></p>
<ol>
<li><code>free -h</code></li>
<li><code>free -s 5</code> show latest memory usage per 5 seconds</li>
<li><code>top</code></li>
<li><code>du --max-depth=1 -h</code> 当前目录下各个子目录的大小</li>
</ol>
<h1>Service</h1>
<ol>
<li><code>systemctl</code>
<ol>
<li><code>systemctl reboot/shutdown</code></li>
<li><code>systemctl -t service</code></li>
<li><code>systemctl start/status sshd</code></li>
</ol>
</li>
<li><code>systemctl enable sshd.service</code>
<ol>
<li><code>journalctl -f -u sshd</code> find the log of a given service <code>-f</code>: follow(keep reading) <code>-u</code>: unit</li>
<li><code>journalctl --since yesterday</code></li>
<li><code>journalctl --since &quot;2015-11-10 14:00:00&quot;</code></li>
</ol>
</li>
</ol>
<h1>File System Mounting</h1>
<h1>Networking</h1>
<ol>
<li><code>ip addr</code></li>
<li><code>cat /etc/resolv.conf</code> DNS server address to use for DNS queries</li>
<li><code>ss</code> another utility to investigate sockets
<ol>
<li><code>ss -tlpn</code> (<code>t</code>: tcp, <code>l</code>: listen state, <code>p</code>: process, <code>n</code>: numeric port) see ports and relevant processes</li>
<li><code>ss -tapn</code> (show all state)</li>
</ol>
</li>
<li><code>traceroute/tracepath www.google.com</code>  show the full route of a network packet from the system to any given host.</li>
</ol>
<h2 id="ssh">ssh</h2>
<p><code>vim /etc/ssh/sshd_config</code> to disable password login for ssh</p>
<h1>watch</h1>
<ol>
<li><code>watch -n 1 &quot;ss -ltp&quot;</code> execute a program periodically, showing output fullscreen</li>
</ol>
<h1>Linux Firewall</h1>
<h2 id="install">install</h2>
<p><code>apt install iptables-persistent</code><br>
iptables: administration tool for IPv4/IPv6 packet filtering and NAT(Network Address Translation)</p>
<ol>
<li><code>iptables -nvL --line-number</code> shows the default table filter and all chains and rules inside of it<br>
see more details in pdf chapter “Linux Firewall”</li>
</ol>
<h1>Disk</h1>
<p><a href="https://www.binarytides.com/linux-command-check-disk-partitions/">Reference</a></p>
<ol>
<li><code>fdisk -l</code></li>
<li><code>sfdisk -l</code></li>
<li><code>df -h</code> <code>h</code>: --human-readable (df shows only the mounted file systems or partitions and not all.)</li>
<li><code>df -h --output=source,fstype,size,used,avail,pcent,target -x tmpfs -x devtmpfs</code> output with specific formats<br>
<code>-x</code> means not shows whose type is any of these</li>
<li><code>lsblk</code> List Block Devices</li>
</ol>
<h1>Others</h1>
<p><a href="https://www.tecmint.com/useful-linux-commands-for-newbies/">Reference</a></p>
<ol>
<li><code>md5sum/sha1sum filename</code></li>
<li><code>uname -a</code> print detailed information about the machine name, Operating System and Kernel.<br>
(kernel name, node name, kernel release, kernel version, )</li>
<li><code>cat /etc/os-release</code></li>
<li><code>sudo</code> stands for super user do</li>
<li><code>touch filename</code> touch command creates the file, only if it doesn’t exist.<br>
If the file already exists it will update the timestamp and not the contents of the file.</li>
<li><code>whatis ls</code></li>
<li><code>alias l='ls -l'</code> <code>unalias l</code></li>
<li><code>cmp filename1 filename2</code></li>
<li><code>w</code> a combination of <code>uptime</code> and <code>who</code></li>
<li><code>rsync</code> a fast, versatile, remote (and local) file-copying tool, which can replace <code>cp</code></li>
<li><code>lsof</code> list of open file <a href="https://www.tecmint.com/10-lsof-command-examples-in-linux/">See More Details</a></li>
<li><code>more/less</code> does not have to read the entire input file before starting(vim does)</li>
<li><code>head/tail</code> read file from head/tail</li>
</ol>
<h2 id="how-to-find-files-or-directories">How to find files or directories</h2>
<ol>
<li><code>locate java</code> locate reads one or more databases prepared by <code>updatedb</code> and writes file names matching at least<br>
one of the PATTERNs to standard output, one per line.</li>
<li><code>which java</code>  find the exact path of the executable being used by a command in our shell.</li>
<li><code>whereis java</code> locate the binary, source, and manual page files for a command(ie, not only the executable one in <code>which</code>, and some other stuff (like man pages).)</li>
<li><strong>find</strong> Search for files in the given directory, hierarchically starting at the parent directory and moving to sub-directories.
<ol>
<li><code>find -name *.sh</code></li>
<li><code>find -iname *.SH</code> case insensitive</li>
</ol>
</li>
<li><strong>grep</strong>
<ol>
<li><code>grep tecmint /etc/passwd</code></li>
<li><code>grep -i TECMINT /etc/passwd</code> case insensitive</li>
<li><code>grep -r &quot;127.0.0.1&quot; /etc/</code> search recursively</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>Interview</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Computer Network总结</title>
    <url>/2020/cklqjzouw000couq1b4r4ey18/</url>
    <content><![CDATA[<h1>Layers</h1>
<ol>
<li>
<p>OSI           : 应用层，表示层，会话层(SSL,TLS)，运输层，网络层，数据链路层，物理层</p>
</li>
<li>
<p>TCP/IP        : 应用层，运输层，网际层，网络接口层</p>
</li>
<li>
<p>Five Protocols: 应用层，运输层，网络层，数据链路层，物理层</p>
</li>
<li>
<p>应用层(application-layer): 应用进程之间的通讯和交互规则. e.g. DNS, HTTP, SMTP(电子邮件)</p>
</li>
<li>
<p>运输层(transport-layer): 负责向两台主机进程之间的通信提供数据传输服务</p>
<ol>
<li>传输控制协议 TCP(Transmission Control Protocol)</li>
<li>用户数据协议 UDP(User Datagram Protocol)</li>
</ol>
</li>
<li>
<p>网络层(IP, Internet Protocol): 选择合适的网间路由和交换结点</p>
<ol>
<li>ping协议 ICMP(Internet Control Message Protocol)Internet控制消息协议，是TCP/IP的一个子协议</li>
</ol>
</li>
<li>
<p>数据链路层(data link layer): 两台主机之间的数据传输，总是在一段一段的链路上传送的</p>
</li>
<li>
<p>物理层(physical layer): 相邻计算机节点之间比特流的透明传送</p>
</li>
</ol>
<h1>TCP</h1>
<p><a href="https://zhuanlan.zhihu.com/p/53374516">TCP连接和释放 Reference1</a><br>
<a href="https://blog.csdn.net/qzcsu/article/details/72861891">TCP连接和释放 Reference2</a></p>
<h2 id="tcp报文格式">TCP报文格式</h2>
<p><img src="https://pic1.zhimg.com/v2-8f5725f163d7f6390a75f3a2d337bc1c_r.jpg" alt="TCP报文格式"></p>
<h2 id="tcp连接-三次握手">TCP连接（三次握手）</h2>
<p><img src="https://pic4.zhimg.com/80/v2-07c065a0321f887ae69e269d8dda9f43_1440w.jpg" alt="TCP连接"></p>
<ol>
<li>客户端向服务端发送特殊TCP报文段-SYN报文段（不包含应用层信息，且该报文段被封装在IP数据报中）
<ol>
<li>SYN置1</li>
<li>SeqNum=client_isn(随机选择)</li>
</ol>
</li>
<li>服务器读取SYN报文段并为该TCP连接分配TCP缓存和变量，发送允许连接的报文段（同样不包含应用层信息）- SYNACK segment
<ol>
<li>SYN置1</li>
<li>ACK置1</li>
<li>AckNum=client_isn+1</li>
<li>SeqNum=server_isn(随机选择)</li>
</ol>
</li>
<li>收到SYNACK segment后，客户端为该连接分配缓存和变量
<ol>
<li>SYN置0(因为连接已经建立)</li>
<li>ACK置1</li>
<li>AckNum=server_isn+1</li>
<li>SeqNum=client_isn+1</li>
</ol>
</li>
</ol>
<p>之后发送的报文SYN都为0</p>
<p><strong>为什么要三次握手</strong></p>
<ol>
<li>第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常</li>
<li>第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常</li>
<li>第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常</li>
</ol>
<p>所以三次握手就能确认双发收发功能都正常，缺一不可。</p>
<h2 id="tcp中止连接-四次挥手">TCP中止连接(四次挥手)</h2>
<p><img src="https://pic3.zhimg.com/80/v2-629f51f6f535ebd7683f944707b21d1e_1440w.jpg" alt="TCP断开连接"><br>
（此过程可以相反：服务端-&gt;客户端）</p>
<ol>
<li>客户端-&gt;服务端
<ol>
<li>FIN置1</li>
<li>SeqNum=client_isn</li>
</ol>
</li>
<li>服务端-&gt;客户端
<ol>
<li>ACK置1</li>
<li>AckNum=client_isn+1</li>
</ol>
</li>
<li>服务器-&gt;客户端
<ol>
<li>FIN置1</li>
<li>SeqNum=server_isn</li>
</ol>
</li>
<li>客户端-&gt;服务端
<ol>
<li>ACK置1</li>
<li>ACKNum=server_isn+1</li>
</ol>
</li>
<li>time_wait=2*MSL(Maximum Segment Lifetime 最大报文生存时间)<a href="https://blog.csdn.net/L_XRUI/article/details/75110377">Reference</a>
<ol>
<li>可靠地实现TCP全双工连接的释放：客户端发送的ACK可能会丢失，服务端会重发一个结束豹纹，所以需要维持time_waited状态来重发可能丢失的ACK</li>
<li>保证让迟来的报文段有足够的时间被识别丢弃：当一个TCP连接处在TIME_WAIT状态，它则会依然占用当前的端口，新的连接时无法立即使用的，<br>
但当没有这个状态，当立即有新的TCP连接时，其会使用与刚才相同的IP地址与端口号，此时这个新的连接则极有可能收到原来连接的迟到的TCP报文段，<br>
这明显是不应该发生的，所以设置这个状态是极有必要的。</li>
<li>为什么是2MSL：由于TCP报文段最大生存时间为MSL,其保持2MSL时间可以确保网络上两个传输方向的尚未接收到的、迟到的报文段都已经消失，<br>
或被路由器丢弃，而2MSL时间后建立新的连接其绝不会收到原来连接的应用程序数据。</li>
</ol>
</li>
<li>close_wait</li>
</ol>
<h2 id="为什么建立连接是三次握手-而关闭连接却是四次挥手呢？">为什么建立连接是三次握手，而关闭连接却是四次挥手呢？</h2>
<p>这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。<br>
而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定。<br>
因此，己方ACK和FIN一般都会分开发送。</p>
<h2 id="isn-initial-sequence-number">ISN(Initial Sequence Number)</h2>
<p>ISN = M + F(localhost, local port, remote host, remote port)<br>
M是一个计时器，每隔4毫秒加1。<br>
F是一个Hash算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值。要保证hash算法不能被外部轻易推算得出。</p>
<h2 id="syn-flood攻击">SYN flood攻击</h2>
<p>问题描述：如果恶意的向某个服务器端口发送大量的SYN包，则可以使服务器打开大量的半开连接，分配TCB（Transmission Control Block）,<br>
从而消耗大量的服务器资源</p>
<p>解决方法：</p>
<ol>
<li>无效连接的监视释放: 监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源</li>
<li>延缓TCB分配方法: 消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。<br>
而SYN Flood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。<br>
常见的方法是使用Syn Cache和Syn Cookie技术。
<ol>
<li>Syn Cache: 系统在收到一个SYN报文时，在一个专用HASH表中保存这种半连接信息，直到收到正确的回应ACK报文再分配TCB。<br>
这个开销远小于TCB的开销。当然还需要保存序列号。</li>
<li>Syn Cookie: 给对方发一个特殊的SeqNum，之后通过接受到的SeqNum-1判断是否给他分配TCB</li>
</ol>
</li>
</ol>
<h2 id="连接队列">连接队列</h2>
<p><img src="https://pic2.zhimg.com/80/v2-c4688fba5db30b31c913f549108c9735_1440w.jpg" alt="连接队列"></p>
<h2 id="tcp-vs-udp">TCP vs UDP</h2>
<p><a href="https://user-gold-cdn.xitu.io/2018/4/19/162db5e97e9a9e01?imageView2/0/w/1280/h/960/format/webp/ignore-error/1">TCP vs UDP</a></p>
<h2 id="tcp如何保证可靠">TCP如何保证可靠</h2>
<p><a href="http://www.52im.net/thread-515-1-1.html">Reference</a><br>
<a href="https://juejin.im/post/5c8f615ff265da612009824a">Reference</a></p>
<ol>
<li>数据合理分片和排序
<ol>
<li>应用数据被分割成TCP认为最适合发送的数据块(according to MTU(Maximum Transmission Unit))</li>
<li>TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层</li>
</ol>
</li>
<li>校验和(checksum)：发送方将伪首部、TCP首部、TCP数据使用累加和校验的方式计算出一个数字，然后存放在首部的校验和字段里，<br>
接收者收到TCP包后重复这个过程，然后将计算出的校验和和接收到的首部中的校验和比较，如果不一致则说明数据在传输过程中出错</li>
<li>TCP的接收端会丢弃重复或损坏的数据，并请求重传</li>
<li>超时重传：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。<br>
<a href="https://blog.csdn.net/wdscq1234/article/details/52476231">超时重传例子</a></li>
<li>流量控制：当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止分组丢失。(根据情况调整接受窗口的大小)</li>
<li>拥塞控制：当网络拥塞时，减少数据的发送
<ol>
<li>慢启动(指数规律增长)</li>
<li>拥塞避免(加法增大)</li>
<li>拥塞发生(乘法减小)</li>
<li>快速恢复(加法增大)<br>
<img src="https://images2015.cnblogs.com/blog/476810/201605/476810-20160508191048124-524427818.jpg" alt="拥塞控制"></li>
</ol>
</li>
<li>滑动窗口：
<ol>
<li>发送方滑动窗口：Sent &amp; Ack, Sent &amp; NotAck, BytesReceiverReadyToAccept, BytesReceiverNotReadyToAccept</li>
<li>TCP确认机制是累计的，即确认的数字之前的包全都收到了</li>
<li>重传机制</li>
</ol>
</li>
</ol>
<h1>UDP</h1>
<p>User Datagram Protocol，是一种无连接的协议。<br>
不保证能否到达目的地，到达时间以及内容的正确性<br><br>
<img src="https://img-blog.csdn.net/20131022143815187?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHVvemVuZ2h1aTUyOTQ4MDgyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="UDP Segment"></p>
<h2 id="在视频中使用udp还是tcp">在视频中使用UDP还是TCP</h2>
<p>为了保证实效性和流畅性UDP更好，因为TCP有一帧卡住的话会一直卡着，且udp不需要握手连接，启动时更快</p>
<h1>Others</h1>
<h2 id="get和post区别">Get和Post区别</h2>
<ol>
<li>GET参数通过URL传递(不能传递敏感信息)；POST放在Request body中</li>
<li>GET产生一个TCP数据包；POST产生两个<br>
2.1. GET: 浏览器会把http header和data一起发出去<br>
2.2. POST: 浏览器先发header，服务器响应100 continue，浏览器再发data，服务器响应200 ok</li>
<li>GET：后退按钮，刷新无害；POST：数据会被重新提交</li>
<li>GET参数可以保存在浏览器历史记录中；POST则不会</li>
</ol>
<h2 id="从输入url到页面加载发生了什么">从输入URL到页面加载发生了什么</h2>
<ol>
<li>DNS解析</li>
<li>TCP连接</li>
<li>发送http请求</li>
<li>服务器处理请求并返回http报文</li>
<li>浏览器解析渲染页面</li>
<li>连接结束</li>
</ol>
<h1>HTTP</h1>
<h2 id="https">HTTPS</h2>
<p><a href="https://zhuanlan.zhihu.com/p/43789231">Reference</a></p>
<h2 id="request头">Request头</h2>
<ol>
<li>Accept: test/html, application/xml -&gt; 告诉服务器客户端的数据格式</li>
<li>Accept-Encoding: gzip -&gt; 支持的压缩格式</li>
<li>Accept-language: -&gt; 支持的语言</li>
<li>Cache-control: -&gt; 告诉服务器是否缓存 <a href="https://juejin.cn/post/6844903683046506504">Reference</a><br>
4.1. 可缓存性:<br>
4.1.1. public(任何路径都可以)<br>
4.1.2. private(只有发起请求的浏览器才可以进行缓存)<br>
4.1.3. no-cache(即使没过期浏览器也要向服务器验证，不会从缓存读取)<br>
4.2. 到期: max-age=<br>
4.3. 其他<br>
4.3.1. no-store(即使服务器下发了缓存相关头，浏览器也会忽略任何和缓存相关的信息，发送请求不会携带相关头，直接去请求最新的数据)</li>
<li>Connection: keep-alive -&gt; 保持TCP连接</li>
<li>Host: <a href="http://www.google.com">www.google.com</a> -&gt; 服务器域名</li>
<li>User-agent: -&gt; 客户端浏览器的信息</li>
</ol>
<h2 id="response头">Response头</h2>
<ol>
<li>Access-Control-Allow-Origin: *</li>
<li>Connection: close</li>
<li>Content-Length: 43</li>
<li>Content-Type: image/gif</li>
<li>Date: Wed, 09 Sep 2020 05:49:48 GMT</li>
<li>Server: Tengine -&gt; ngnix服务器类型</li>
</ol>
<h2 id="http多路复用">HTTP多路复用</h2>
<p><a href="https://user-gold-cdn.xitu.io/2019/9/5/16cff873bf2ec175?imageView2/0/w/1280/h/960/format/webp/ignore-error/1">http多路复用</a></p>
<h1>Network Program</h1>
<h2 id="socket-套接字">Socket（套接字）</h2>
<ol>
<li>文件描述符，代表一个通信管道，可以进行read, write, close等类文件操作函数</li>
<li>创建: <code>socket(int family, int type, int protocol)</code><br>
2.1. family:   协议族(AF_INET, AF_INET6, PF_PACKET等)<br>
2.2. type:     套接字类(SOCK_STREAM, SOCK_DGRAM, SOCK_RAW等)<br>
2.3. protocol: 协议类别(0, IPPROTO_TCP, IPPROTO_UDP等)</li>
<li>绑定: <code>bind()</code>将服务器ip+port和socket绑定</li>
<li>字节序（小端格式：低位字节存在低地址，大端格式：高位字节存在低地址）<br>
4.1. htonl, htons: host to network, l: 32 bit, s: 16 bit<br>
4.2. ntohl, ntohs: network to host</li>
</ol>
<h3 id="sock-raw">SOCK_RAW</h3>
<p>附加协议: <code>#include&lt;netinet/ether.h&gt;</code><br>
ETH_P_ALL(所有协议对应的数据包)<br>
ETH_P_IP(ip数据包)<br>
ETH_P_ARP(arp数据包)</p>
<h2 id="udp">UDP</h2>
<p>TFTP,<br>
广播：由一台主机向所有子网内的主机发送数据的方式<br>
多播：数据的收发仅在同一分组中进行</p>
<h2 id="tcp">TCP</h2>
<h3 id="tcp不能实现并发的原因">TCP不能实现并发的原因</h3>
<p>有两个读阻塞函数(accept &amp; recv)</p>
<h3 id="多进程-线程-实现并发">多进程(线程)实现并发</h3>
<ol>
<li>在accept之后fork，每个子进程进行recv/send</li>
<li>在accept之后<code>pthread_create()</code>，每个子线程进行recv/send</li>
</ol>
<h1>ARP(地址解析协议) Address Resolution Protocol</h1>
<h2 id="cdn-content-delivery-network">CDN(Content Delivery Network)</h2>
<p>CDN是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，<br>
通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，<br>
降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。</p>
]]></content>
      <categories>
        <category>Interview</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Algorithm</tag>
        <tag>Big Data Scenario</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/cklqjzoux000douq1el45b3ll/</url>
    <content><![CDATA[<h1>产品参数</h1>
<ol>
<li>塑料款 12L 235<em>195</em>310mm 无内桶<br>
1.1. 电池单模式<br>
1.1.1. 两节五号干电池（赠品）：按一天20次开合，3-6个月<br>
1.2. 电池三模式<br>
1.2.1. 两节五号干电池（赠品）：按一天20次开合，3-6个月<br>
1.3. 充电三模式<br>
1.3.1. 内置锂电池：3-4小时充满，按不同使用频率，3-6个月</li>
<li>不锈钢款 12L 250<em>250</em>345mm 有内桶<br>
2.1. 充电三模式（香槟金，玫瑰金，砂钢）<br>
2.1.1. 内置锂电池：3-4小时充满，按不同使用频率，3-6个月</li>
<li>垃圾袋尺寸：45*50</li>
</ol>
<h1>快递区域</h1>
<p>[快递区域](File:///Users/ronan/merchant/express.xlsx)</p>
<h1>物品损坏</h1>
<ol>
<li>自动回复中选择相应选项让买家拍照片<br>
1.1. 确认包装箱是否损坏<br>
1.2. 产品破损拍照<br>
1.3. 说是快递暴力的问题</li>
<li>盖子损坏：申请换货，把盖子寄回来，有退货物流信息就（收到再）补发</li>
<li>桶损坏：补发桶</li>
<li>补发会提供单号，记得查收</li>
</ol>
<h1>物品不感应</h1>
<h1>发货</h1>
<ol>
<li>提供单号</li>
<li>发货时间一般是：16点之前的订单当天发，之后的次日发货</li>
</ol>
<h1>额外返现</h1>
<ol>
<li>提供五星好评和追评的图片返1元</li>
<li>关注店铺返1元</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Redis个人总结</title>
    <url>/2020/cklqjzouz000gouq12btibjul/</url>
    <content><![CDATA[<p><a href="https://redislabs.com/ebook/preface/">Book Reference</a></p>
<h1>Features</h1>
<ol>
<li>In-memory(store data in RAM) non-relational database(No SQL)</li>
<li>flush to disk when
<ol>
<li>a point-in-time dump either when certain conditions are met (a number of writes in a given period)</li>
<li>one of the two dump-to-disk commands is called.</li>
</ol>
</li>
<li>Supports master/slave replication where slaves connect to the master and receive an initial copy of the full database.
<ol>
<li>support higher rates of read performance</li>
<li>writes are performed on the master</li>
</ol>
</li>
<li>No need to go through a query parser/optimizer</li>
<li>Update an existing row is always fast</li>
<li>don’t allow nested structure</li>
</ol>
<h1>vs Memcached</h1>
<ol>
<li>Memcached uses a blacklist to hide items that is removed, in Redis, use <code>remove</code> to remove item directly</li>
</ol>
<h1>Data Structures and Commands</h1>
<p><a href="http://redis.io/commands">Redis Commands</a></p>
<h2 id="strings">Strings</h2>
<p>Strings has three types:</p>
<ol>
<li>Byte string Values (each character has 8 bits)</li>
<li>Integer values</li>
<li>Floating-point values</li>
</ol>
<p>Commands:</p>
<ol>
<li>Basic:
<ol>
<li><code>set hello world</code></li>
<li><code>get hello</code></li>
<li><code>del hello</code></li>
</ol>
</li>
<li>Numeric Operation:
<ol>
<li><code>incr/decr key</code> (the value of this key must be Integer or Floating-point)</li>
<li><code>incrby/decrby key amount</code></li>
<li><code>incrbyfloat key amout</code></li>
</ol>
</li>
<li>Substring Manipulation:
<ol>
<li><code>append key append-value</code> (concatenate)</li>
<li><code>getrange key start end</code> (fetch substring)</li>
<li><code>setrange key offset value</code> (replace offset^{th} element with value)</li>
<li><code>bitcount key</code> count the number of 1 in the string</li>
<li><code>getbit key offset</code></li>
<li><code>setbit key offset value</code></li>
</ol>
</li>
</ol>
<h2 id="lists">Lists</h2>
<ol>
<li><code>lpush/rpush list-key item</code></li>
<li><code>lpop/rpop list-key item</code></li>
<li><code>lindex list-key 1</code> (the second item in this list)</li>
<li><code>lrange list-key 0 2</code> (list out the first three items)</li>
<li><code>lrange list-key 0 -1</code> (list out all items in this list)</li>
<li><code>ltrim list-key start end</code> ( Trims the list to only include items at indices between start and end, inclusive)</li>
<li><code>blpop/brpop list-key1 list-key2 ... timeout</code> (Pops the leftmost item from the first non-empty LIST, or waits the timeout in seconds for an item)</li>
<li><code>rpoplpush source-key dest-key</code></li>
<li><code>brpoplpush source-key dest-key timeout</code></li>
</ol>
<p>Can be used as stack or queue, which is similar to Deque in Java</p>
<h2 id="sets">Sets</h2>
<p>use a hash table to keep all strings unique</p>
<ol>
<li>Basic:
<ol>
<li><code>sadd set-key item</code></li>
<li><code>smembers set-key</code> (list out all items in this set)</li>
<li><code>sismember set-key item</code> (check whether item is in this set or not)</li>
<li><code>srem set-key item</code> (remove item from set, return 1 if success, 0 if fail)</li>
<li><code>scard set-key</code> (print the number of items in this list)</li>
<li><code>spop set-key</code> removes and returns a random item from the SET</li>
<li><code>srandmember set-key [count]</code> Returns one or more random items from the SET. When count is positive,<br>
Redis will return count distinct randomly chosen items, and when count is negative,<br>
Redis will return count randomly chosen items that may not be distinct.</li>
<li><code>smove source-key dest-key item</code> If the item is in the source,<br>
removes the item from the source and adds it to the destination</li>
</ol>
</li>
<li>Operations for combining and manipulating
<ol>
<li><code>sdiff/sinter/sunion key1 key2 key3 ...</code></li>
<li><code>sdiffstore/sinterstore/sunionstore dest-key key1 key2 key3 ...</code></li>
</ol>
</li>
</ol>
<h2 id="hashes">Hashes</h2>
<p>Similar to HashMap in Java</p>
<ol>
<li><code>hset hash-key sub-key1 value1</code> (return 1 if sub-key1 is new, 0 if not)</li>
<li><code>hmset hash-key sub-key1 value1 [sub-key2 value2]</code></li>
<li><code>hget hash-key sub-key1</code></li>
<li><code>hmget hash-key sub-key1 sub-key2</code></li>
<li><code>hgetall hash-key</code> (each entry will print into two rows, one for key, one for value)</li>
<li><code>hdel hash-key sub-key1</code></li>
<li><code>hlen hash-key</code></li>
<li><code>hexists hash-key sub-key</code></li>
<li><code>hkeys hash-key</code></li>
<li><code>hvals hash-key</code></li>
<li><code>hincrby hash-key sub-key increment</code></li>
<li><code>hincrbyfloat hash-key sub-key increment</code></li>
</ol>
<h2 id="sorted-sets-zsets">Sorted Sets(ZSets)</h2>
<p>Also hold a type of key and value.<br>
The keys (called <strong>members</strong>) are unique, and the values (called <strong>scores</strong>) are limited to floating-point numbers.</p>
<ol>
<li><code>zadd zset-key &lt;score&gt; &lt;member&gt;</code></li>
<li><code>zrange zset-key 0 -1 withscores</code><br>
(list out all items in this set in order, each entry will print into two rows, one for member, one for scores)</li>
<li><code>zrange zset-key 0 2 withscores</code> (print the first three members (with scores) in this set)</li>
<li><code>zrangebyscore/zrevrangebyscore zset-key 1 24 withscores</code> (print members with scores between 1 and 24)</li>
<li><code>zrem zset-key member</code></li>
<li><code>zscore zset-key member</code></li>
<li><code>zcard zset-key</code> (print out the size of this zset)</li>
<li><code>zcount zset-key min max</code> (count scores between min and max)</li>
<li><code>zrank/zrevrank zset-key member</code> (the position of the given member in order/reverse order)</li>
<li><code>zinterstore/zunionstore dest-key key-count zset-key set-key aggragate min/sum/max</code> default function is sum<br>
<a href="https://redislabs.com/ebook/part-2-core-concepts/chapter-3-commands-in-redis/3-5-sorted-sets/">process of union and intersection</a></li>
</ol>
<h2 id="publish-subscribe">Publish/Subscribe</h2>
<ol>
<li>Reasons that don’t use it often
<ol>
<li>send but no read(cause buffer too large, which may result in redis kill or system unavailable),<br>
configure <code>client-output-buffer-limit pubsub</code> to avoid large buffer</li>
<li>data transmission reliability: subscriber may disconnect with channel</li>
</ol>
</li>
<li>Commands
<ol>
<li><code>subscribe channel</code></li>
<li><code>unsubscribe channel</code></li>
<li><code>publish channel message</code></li>
</ol>
</li>
</ol>
<h2 id="sort">Sort</h2>
<p>Three types can be sorted: list, set, zset at key<br>
Before sort, data strcture will be converted to double</p>
<ol>
<li><code>sort list-key limit 0 5 alpha desc</code></li>
<li><code>sort hkey</code></li>
</ol>
<h2 id="transaction">Transaction</h2>
<ol>
<li>Cannot be executed partially and then rollback or commit</li>
<li>Improve performance since the number of round trips between Redis and client is reduced</li>
<li>Commands
<ol>
<li>input <code>multi</code></li>
<li>input all commands that you want in this transaction</li>
<li>input <code>exec</code> then redis will execute all commands sequentially without interruption(<code>pipeline</code> in python)</li>
</ol>
</li>
</ol>
<h2 id="expiring-keys">Expiring keys</h2>
<ol>
<li><code>persist key-name</code>  (Removes the expiration from a key)</li>
<li><code>ttl key-name</code> (Returns the amount of time(seconds) remaining before a key will expire)</li>
<li><code>expire key-name seconds</code> 倒计时</li>
<li><code>expireat key-name timestamp</code> 定时</li>
<li><code>pttl key-name</code> (milliseconds)</li>
<li><code>pexpire key-name milliseconds</code> 倒计时</li>
<li><code>pexpireat key-name timestamp-milliseconds</code> 定时</li>
</ol>
<h1>Usage of Redis</h1>
<h2 id="login-and-cookie-caching">Login and cookie caching</h2>
<h2 id="shopping-carts-in-redis">Shopping carts in Redis</h2>
<h2 id="web-page-caching">Web page caching</h2>
<h2 id="database-row-caching">Database row caching</h2>
<ol>
<li><code>set row_id json.dumps(row.to_dict())</code> use strings to cache row, use id as key, use json format as value</li>
</ol>
<h2 id="web-page-analysis">Web page analysis</h2>
<h1>Cases</h1>
<p><a href="https://blog.csdn.net/zeb_perfect/article/details/54135506">缓存问题 Reference1</a><br>
<a href="https://www.javazhiyin.com/54503.html">缓存问题 Reference2</a></p>
<h2 id="缓存雪崩">缓存雪崩</h2>
<p>问题描述：所有key在同一时间失效，那么请求全部落数据库，数据库负载很大<br><br>
解决方法：</p>
<ol>
<li>Redis设置key的expire time的时候，在原有的时间上加一个随机值，或者热点数据不过期（有更新操作就更新缓存）</li>
<li>加锁或队列方式保证缓存单线程写，从而避免失效时大量的并发请求落到底层存储系统上</li>
<li>数据预热：系统上线后，将相关的缓存数据直接加载到缓存系统</li>
<li>双层缓存策略：C1为原始缓存，C2为拷贝缓存，C1失效时，可以访问C2，C1缓存失效时间设置为短期，C2设置为长期</li>
<li>定时更新缓存策略：实效性要求不高的缓存，容器启动初始化加载，采用定时任务更新或移除缓存</li>
</ol>
<h2 id="缓存穿透">缓存穿透</h2>
<p>问题描述：指缓存和数据库中都没有的数据，因此数据不会写入缓存，而用户不断发起该数据的请求都会让系统去DB查询；<br>
攻击者可以利用不存在的key攻击该服务<br><br>
解决方法：</p>
<ol>
<li>布隆过滤器：将所有可能存在的数据hash到一个bitmap中，通过hash key来过滤不存在的值</li>
<li>增加校验，比如拦截id&lt;=0</li>
<li>将查询返回为空的数据缓存，设置一个较短的过期时间（设置太长会导致正常情况也没法使用）</li>
</ol>
<h2 id="缓存击穿">缓存击穿</h2>
<p>问题描述：某些过期的key可能在某个时间点被超高频率访问（&quot;热点&quot;数据），与雪崩不同之处在于，雪崩是很多key，这个是一个key<br><br>
解决方法：</p>
<ol>
<li>热点数据永不过期</li>
<li>使用互斥锁(mutex key)：多个线程同时去查询数据库的这条数据，在第一个查询数据的请求上使用一个互斥锁来锁住它<br>
其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存</li>
<li>&quot;提前&quot;使用互斥锁</li>
<li>资源隔离组件hystrix</li>
</ol>
<h1>Persistence</h1>
<h2 id="snapshotting">Snapshotting</h2>
<h2 id="aof-append-only-file">AOF(Append-only file)</h2>
]]></content>
      <categories>
        <category>Interview</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>OS个人总结</title>
    <url>/2020/cklqjzov0000houq18u0k8k1f/</url>
    <content><![CDATA[<h1>CPU Context Switch</h1>
<p><a href="https://zhuanlan.zhihu.com/p/52845869">CPU上下文切换 Reference1</a><br>
<a href="https://baike.baidu.com/item/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2">CPU上下文切换 Reference2</a></p>
<ol>
<li>CPU切换到另一个程序需要保存当前程序的状态并恢复另一个程序的状态</li>
<li>类型
<ol>
<li>进程上下文切换: 操作PCB</li>
<li>线程上下文切换
<ol>
<li>若两个线程在不同进程，切换过程同进程</li>
<li>若两个线程在同一进程，只需切换线程私有数据，寄存器等不共享的数据（无需切换虚拟内存，全局变量等）</li>
</ol>
</li>
<li>中断上下文切换</li>
</ol>
</li>
</ol>
<h1>互斥和同步</h1>
<p><a href="https://blog.csdn.net/ns_code/article/details/17284351">Reference</a></p>
<ol>
<li>临界资源: 能够被多个线程共享的数据/资源</li>
<li>临界区: 对临界资源进行操作的那一段代码</li>
<li>互斥: 指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性</li>
<li>同步: 指在互斥的基础上，通过其它机制实现访问者对资源的有序访问</li>
</ol>
<h1>Thread</h1>
<p><a href="https://baike.baidu.com/item/%E7%BA%BF%E7%A8%8B">线程-百度百科</a></p>
<ol>
<li>线程控制块TCB(Thread Control Block)，数据段和代码段</li>
<li>调度的基本单位</li>
<li>共享：进程中的全部系统资源，如虚拟地址空间，文件描述符，信号处理等</li>
<li>独有：调用栈(call stack)，寄存器环境(register context)，线程本地存储(thread-local storage)</li>
<li>线程间可以直接读写进程数据段（如全局变量）来进行通信，需要同步互斥来保证数据一致性</li>
<li>上下文切换比进程快得多</li>
</ol>
<h2 id="thread-communication">Thread Communication</h2>
<p><a href="https://blog.csdn.net/qq_33951180/article/details/72801228">线程的同步和互斥</a><br>
<a href="https://github.com/clpsz/linux-itss">Thread Communication</a></p>
<ol>
<li>同一个进程的多个线程在同一个地址空间，通信是很容易的事情，因此多线程间要同步就好了。</li>
<li>同步方式<br>
<a href="https://zhuanlan.zhihu.com/p/40729293">自旋锁&amp;互斥锁1</a><br>
<a href="https://blog.csdn.net/electrocrazy/article/details/78931704">自旋锁&amp;互斥锁2</a>
<ol>
<li>互斥锁/量(Mutex): 当线程在获取锁时，若锁已被其它线程获取，该线程将睡眠
<ol>
<li>线程进入阻塞状态，进入内核态，获取到锁时又恢复到用户态，过程伴随线程上下文切换，cpu抢占，信号的发送等开销</li>
<li>适合于临界区持锁事件较长的操作，比如IO读写等</li>
</ol>
</li>
<li>自旋锁: 当线程在获取锁时，若锁已被其它线程获取，该线程将循环等待，之后不断判断锁是否能被获取，直到获取到锁才退出循环
<ol>
<li>过程不会发生线程上下文切换</li>
<li>若某个线程持有锁时间过长，使其他线程一直busy waiting，消耗CPU资源</li>
<li>Java实现的自旋锁是非公平的，存在&quot;线程饥饿&quot;问题</li>
<li>可重入/不可重入自旋锁</li>
<li>Java中TicketLock，公平的自旋锁（给线程分配ticketNum，每当释放锁serviceNum+1，之后和ticketNum对应的线程获得锁）</li>
<li>TicketLock频繁读写serviceNum，解决方法：CLHLock和MCSLock(基于链表和前驱节点是否被占用来判断是否可以获得锁)</li>
</ol>
</li>
<li>信号量(Semaphore)
<ol>
<li>临界资源可以有n个锁</li>
<li>Mutex是Semaphore的一种特殊情况(n=1)</li>
</ol>
</li>
<li><a href="https://oxnz.github.io/2014/04/23/multi-threads-programming/#%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F">条件变量</a></li>
<li>读写锁(共享互斥锁 <a href="https://stackoverflow.com/questions/11837428/whats-the-difference-between-an-exclusive-lock-and-a-shared-lock">shared-exclusive lock</a>)
<ol>
<li>exclusive lock: 有且仅有一个线程能获取</li>
<li>shared lock: 写模式线程无法获取锁，读模式线程可以获取</li>
</ol>
</li>
<li>屏障(barrier)
<ol>
<li>是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从该点继续执行。<br>
pthread_join函数就是一种屏障，允许一个线程等待，直到另一个线程退出。</li>
</ol>
</li>
<li>信号机制：类似进程的信号处理</li>
<li>事件</li>
</ol>
</li>
</ol>
<h1>Process</h1>
<p><a href="https://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html">进程与线程的一个简单解释</a></p>
<h2 id="process">Process</h2>
<p><a href="https://baike.baidu.com/item/PCB/16067368">PCB</a></p>
<ol>
<li>进程控制块 PCB(Process Control Block)，数据段和代码段</li>
<li>资源拥有的基本单位，资源被记录在PCB中</li>
<li>进程有各自的虚拟地址空间</li>
<li>在多线程OS中，进程不是一个可执行的实体</li>
<li>进程间通讯IPC</li>
<li>进程状态 <br><br>
<img src="https://img-blog.csdn.net/20170820104536564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcWljaGVuZzc3Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="进程状态"></li>
</ol>
<h2 id="process-communication">Process Communication</h2>
<p><a href="https://segmentfault.com/a/1190000008732448">Communication Reference1</a><br>
<a href="https://www.jianshu.com/p/9218692cb209">Communication Reference2</a><br>
<a href="https://github.com/clpsz/linux-ipcs">Communication Reference3</a></p>
<h2 id="inter-process-communication-ipc-进程间通讯">Inter Process Communication(IPC 进程间通讯)</h2>
<p>Communication Fashions</p>
<ol>
<li>单工：A只能发信号，B只能接受信号</li>
<li>半双工：AB都能发送和接受信号，但是同时只能A发给B或者B发给A</li>
<li>全双工：AB能同时接受和发送信息</li>
</ol>
<p>IPC Fashions</p>
<ol>
<li>管道(pipe)<a href="https://blog.csdn.net/yxtxiaotian/article/details/69568774">Pipe Reference</a>
<ol>
<li>单工，有固定的读端和写端</li>
<li>数据被进程从管道读出后，在管道中该数据就不存在了</li>
<li>管道满了，阻塞写进程；管道空或别的进程在读，阻塞读进程</li>
<li>容量为64KB</li>
<li>无名管道(anonymous pipe)
<ol>
<li>单工，数据单方向流动，双方通信需要建立两个管道</li>
<li>只能用于亲缘关系的进程（主要用于父子进程或兄弟进程之间）</li>
<li>单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，并且只存在与内存中</li>
<li>只有在管道的读端存在时，向管道中写入数据才有意义</li>
<li>依附于进程的生存</li>
<li>若写入数据大于PIPE_BUF大小，则不保证写入的原子性</li>
</ol>
</li>
<li>有名管道(named pipe)
<ol>
<li>提供一个路径名与之关联，以FIFO的文件形式存在于文件系统中（因此通信进程可以不必有亲缘关系）</li>
<li>其他性质与无名管道类似</li>
</ol>
</li>
<li>管道速度慢，容量有限</li>
</ol>
</li>
<li>消息队列(message queue)
<ol>
<li>消息的链接表</li>
<li>容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题</li>
</ol>
</li>
<li>共享内存(shared memory)
<ol>
<li>使得多个进程可以访问同一块内存空间</li>
<li>容量容易控制，速度快</li>
</ol>
</li>
<li>套接字(socket): 可用于不同机器间的通讯</li>
<li>信号量(semaphore)(并不算通信方式，而是同步方式)
<ol>
<li>信号量是一个计数器，可以用来控制多个进程对共享资源的访问</li>
<li>不能传递复杂消息，只能用来同步</li>
</ol>
</li>
<li>信号(signal)(并不算通信方式，而是同步方式)
<ol>
<li>用于通知接受进程某个事件已经发生</li>
<li>除了用于进程间通信外，进程还可以发送信号给进程本身</li>
</ol>
</li>
</ol>
<h1>Coroutine</h1>
<h2 id="协程-coroutine">协程(Coroutine)</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/897692888725344/923057403198272">Reference</a></p>
<ol>
<li>执行效率高。因为子程序切换不是线程切换，而是由程序自身控制，没有线程切换的开销</li>
<li>不需要多线程的锁机制，因为只有一个线程，多个协程工作是通过中断实现，不存在同时写变量冲突，在协程中控制共享资源不加锁</li>
</ol>
<h1>Select, Poll, EPoll</h1>
<h2 id="文件描述符">文件描述符</h2>
<p>Linux中一切皆可以看成是文件(普通文件、目录文件、链接文件和设备文件)<br>
<img src="https://img-blog.csdn.net/20140831224818062?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3l3b3Nw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="文件描述符"><br>
<a href="https://segmentfault.com/a/1190000003063859">Linux IO, Select, Poll, Epoll1</a><br>
<a href="https://embed-linux-tutorial.readthedocs.io/zh_CN/latest/system_programing/socket_io.html">Linux IO, Select, Poll, Epoll2</a></p>
<p>Select, Poll, Epoll都是IO多路复用的机制(一个进程同时处理多个网络IO)<br>
（I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作）。<br>
三者都是同步IO。</p>
<ol>
<li>Select
<ol>
<li>监视的文件描述符: writefds、readfds、和exceptfds。<br>
调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。<br>
当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。</li>
<li>几乎所有平台支持</li>
<li>单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024</li>
</ol>
</li>
<li>Poll
<ol>
<li>没有最大数量限制(select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。<br>
事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。)</li>
<li>和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</li>
</ol>
</li>
<li>Epoll
<ol>
<li><code>int epoll_create(int size)</code> 创建一个epoll的epfd（epoll文件描述符）<br>
告诉内核这个监听的数目一共有多大(参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议)</li>
<li><code>int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)</code> 对指定描述符fd执行op操作</li>
<li><code>int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout)</code> 等待epfd上的io事件，最多返回maxevents个事件</li>
<li>epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知</li>
<li>IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。</li>
<li>两种操作模式<br>
6.1. LT模式：即水平触发模式，当epoll_wait检测到socket描述符处于就绪时就通知应用程序，应用程序可以不立即处理它。下次调用epoll_wait时，还会再次产生通知。<br>
6.2. ET模式：即边缘触发模式，当epoll_wait检测到socket描述符处于就绪时就通知应用程序，应用程序 必须 立即处理它。如果不处理，下次调用epoll_wait时，不会再次产生通知。</li>
</ol>
</li>
</ol>
<h1>Deadlock</h1>
<p>产生死锁的四个必要条件：</p>
<ol>
<li>互斥条件：一个资源每次只能被一个进程使用。</li>
<li>占有且等待：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li>
<li>不可强行占有: 进程已获得的资源，在末使用完之前，不能强行剥夺。</li>
<li>循环等待条件: 若干进程之间形成一种头尾相接的循环等待资源关系。</li>
</ol>
<h1>内存</h1>
<h2 id="页面置换算法">页面置换算法</h2>
<ol>
<li>FIFO</li>
<li>LRU: least recently used</li>
<li>LFU: least frequently used</li>
</ol>
<h2 id="内存缺页错误">内存缺页错误</h2>
<ol>
<li>linux内存采用分页管理<br>
1.1. 将虚拟内存和物理内存分为固定大小的页，交由CPU中的MMU模块来映射<br>
1.2. 好处：允许虚拟内存大于实际物理内存：将长时间不用的数据存储到磁盘上；<br>
减少内存碎片，分配管理的都是页</li>
<li>当进程在进行计算时，CPU会请求内存中存储的数据，CPU发出的地址是虚拟地址，通过MMU(Memory Management Unit)取寻找物理内存页；<br>
若物理内存中没有该页或者该页只读但要进行写操作，则会报告一个缺页错误(Page Fault)</li>
</ol>
<h2 id="虚拟存储器-虚拟内存">虚拟存储器(虚拟内存)</h2>
<p>电脑中所运行的程序均需经由内存执行，若执行的程序占用内存很大或很多，则会导致内存消耗殆尽。<br>
为解决该问题，Windows中运用了虚拟内存技术，即匀出一部分硬盘空间来充当内存使用。<br>
当内存耗尽时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。</p>
<h1>Others</h1>
<h2 id="用户态和内核态">用户态和内核态</h2>
<p>内核态权限最大，可访问内存所有数据，包括外围设备（用户态访问受限）</p>
<h2 id="同步-异步-阻塞-非阻塞">同步 异步 阻塞 非阻塞</h2>
<p><a href="https://www.zhihu.com/question/19732473">同步 异步 阻塞 非阻塞</a></p>
<ol>
<li>同步和异步关注的是消息通信机制<br>
1.1. 所谓同步，就是在发出一个<em>调用</em>时，在没有得到结果之前，该<em>调用</em>就不返回。但是一旦调用返回，就得到返回值了。<br>
由<em>调用者</em>主动等待这个<em>调用</em>的结果。而异步则是相反，<em>调用</em>在发出之后，这个调用就直接返回了，所以没有返回结果。<br>
1.2. 异步过程调用后，调用者不会立刻得到结果。而是在<em>调用</em>发出后，<em>被调用者</em>通过状态、通知来通知调用者，或通过回调函数处理。</li>
<li>阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.<br>
2.1. 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。<br>
2.2. 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</li>
</ol>
<h1>分段和分页</h1>
<p><a href="https://www.cnblogs.com/myseries/p/12487211.html">Reference</a><br>
在早期的计算机中，程序都是直接运行在内存上的，也就是说程序中访问的内存地址都是实际的物理内存地址。</p>
<ol>
<li>进程地址空间不隔离。恶意程序可随意修改别的进程的内存数据，或者bug的程序不小心修改了其它程序的内存数据。</li>
<li>空间碎片</li>
<li>程序运行的地址不确定。因为是随机分配的，所以程序运行的地址是不确定的。</li>
</ol>
<h2 id="分段">分段</h2>
<p>在虚拟地址空间和物理地址空间之间做一一映射，但是每次换入换出内存的都是整个程序</p>
<h2 id="分页">分页</h2>
<p>地址空间分成许多的页。每页的大小由CPU决定，然后由操作系统选择页的大小，一般是4KB或4MB<br>
分页的思想是程序运行时用到哪页就为哪页分配内存，没用到的页暂时保留在硬盘上。<br>
当用到这些页时再在物理地址空间中为这些页分配内存，然后建立虚拟地址空间中的页和刚分配的物理内存页间的映射。</p>
<h3 id="分页例子">分页例子</h3>
<ol>
<li>为程序创建一个4GB的进程虚拟地址空间</li>
<li>创建页目和页表</li>
<li>当CPU要访问程序中用到的某个虚拟地址时，当CPU发现该地址并没有相相关联的物理地址时，<br>
CPU认为该虚拟地址所在的页面是个空页面，CPU会认为这是个页错误(Page Fault)，CPU会将控制权交还给操作系统。<br>
操作系统于是为该程序在物理空间中分配一个页面，然后再将这个物理页面与虚拟空间中的虚拟页面映射起来，然后将控制权再还给进程，进程从刚才发生页错误的位置重新开始执行</li>
</ol>
<h3 id="分页置换算法"><a href="https://blog.csdn.net/u011080472/article/details/51206332">分页置换算法</a></h3>
<ol>
<li>最佳置换算法(Optimal OPT): 置换以后不再被访问，或者在将来最迟才回被访问的页面，缺页中断率最低<br>
(很难估计哪一个页面是以后不再使用或在最长时间以后才会用到的页面。所以该算法是不能实现的)</li>
<li>先进先出置换算法(First In First Out, FIFO):</li>
<li>最近最少使用置换算法（Least Recently Used， LRU）:</li>
</ol>
]]></content>
      <categories>
        <category>Interview</category>
        <category>OS</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>OS</tag>
        <tag>Process</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java面试个人总结</title>
    <url>/2020/cklqjzovr0025ouq1bvihei5t/</url>
    <content><![CDATA[<h1>Collections</h1>
<h2 id="arraylist">ArrayList</h2>
<ol>
<li>newCapacity = oldCapacity + oldCapacity &gt;&gt; 1, namely 1.5 times</li>
<li>use <code>objedt.ensureCapacity(N)</code> before lots of add operations to avoid many capacity growth</li>
<li>use <code>Vector</code> if thread safety is required</li>
</ol>
<h2 id="hashmap">HashMap</h2>
<table>
<thead>
<tr>
<th></th>
<th>Is Thread Safe</th>
<th>Efficiency</th>
<th>Null support</th>
<th>Initial Capacity, Capacity Growth</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>HashMap</td>
<td>No, use concurrentHashMap if needed</td>
<td>faster</td>
<td>Yes</td>
<td>16(2*n)</td>
<td>convert list to red-black tree when list length &gt; 8(default)</td>
</tr>
<tr>
<td>Hashtable</td>
<td>Yes</td>
<td>slower</td>
<td>No</td>
<td>11(2*n+1)</td>
<td>no this mechanism</td>
</tr>
</tbody>
</table>
<ol>
<li><code>hash</code> method(扰动函数): high 16 bits XOR low 16 bits</li>
<li>Use <code>(n - 1) &amp; hash</code> to determine the position of key in the map array.<br>
if length is the power of 2, <code>&amp;</code> operation is faster than <code>%</code> operation (hash % length == hash &amp; (length - 1).<br>
That’s why the length of array in HashMap is the power of 2. Hence, index is relative to the low four bits,<br>
which generate collisions easily. So the designer use high 16 bits XOR low 16 bits to mitigate this kind of collision.</li>
<li>when <code>put</code>, compare hash as well as key</li>
<li><strong>Concurrent HashMap</strong>
<ol>
<li>JDK 1.7 Segment Lock, one segment has a <code>HashEntry</code> array, which is list-like structure. When a thread wants to modify data, it must obtain its segment lock</li>
<li>JDK 1.8 Node array + list + red-black tree + synchronized + CAS, the lock is for the first node(root) of a list or red-black tree,<br>
which means there is no concurrency conflict if hashcode is different.</li>
<li>In Hashtable, it locks the whole table so its efficiency is very low</li>
</ol>
</li>
<li><code>HashSet</code> use <code>HashMap</code> since key in <code>HashMap</code> is unique, when <code>add</code> in <code>HashSet</code>, <code>map.put(ele, new Object())</code></li>
<li>tableSizeFor(int cap): 得到threshold，（不减1，如果原来就是2的幂数，将会得到其两倍，这是不对的）<br>
函数的效果是，cap最高位及后面所有位都是1<br>
original (num - 1) : 1000 0000 0000 0000<br>
n |= n &gt;&gt;&gt; 1       : 1100 0000 0000 0000<br>
n |= n &gt;&gt;&gt; 2       : 1111 0000 0000 0000<br>
n |= n &gt;&gt;&gt; 4       : 1111 1111 0000 0000<br>
n |= n &gt;&gt;&gt; 8       : 1111 1111 1111 1111<br>
n |= n &gt;&gt;&gt; 16      : 32 bits are all 1, which is MAX VALUE of integer</li>
</ol>
<h3 id="解决哈希冲突的常用方法分析">解决哈希冲突的常用方法分析</h3>
<p><a href="https://www.jianshu.com/p/4d3cb99d7580">Reference</a></p>
<ol>
<li>开放定址法: 从发生冲突的那个单元起，按照一定的次序，从哈希表中找到一个空闲的单元
<ol>
<li>线行探查法: 从发生冲突的单元起，依次判断下一个单元是否为空，当达到最后一个单元时，再从表首依次判断。直到碰到空闲的单元或者探查完全部单元为止。</li>
<li>二次探测: 用发生冲突的单元d[i], +1², -1², +2², -2²等，反复横跳！</li>
<li>双散列函数探查法:</li>
</ol>
</li>
<li>拉链法：HashMap</li>
<li>再散列：使用其他hash函数计算</li>
<li>建立公共溢出区: 将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。</li>
</ol>
<h3 id="hashmap-容量为什么是2的幂次方">HashMap 容量为什么是2的幂次方</h3>
<p>为了让(hash%size==hash&amp;(size-1))，位运算 &amp; 比 % 速度要快</p>
<hr>
<h1>Thread</h1>
<h2 id="lifecycle">Lifecycle</h2>
<p>new, runnable, blocked, waiting, time_waiting, terminated</p>
<h2 id="sleep-vs-wait">sleep() vs wait()</h2>
<ol>
<li>sleep doesn’t lose ownership of monitors, but wait does</li>
<li>sleep is used to suspend threads, but wait is used for communication between threads</li>
<li>sleep will resume automatically, but wait won’t unless <code>wait(timeout)</code></li>
<li>both can suspend thread execution</li>
<li>为什么wait在Object中，而sleep在Thread中<br>
5.1. java锁机制中，每个对象都可以成为锁，都可以取调用wait方法，因此wait放在Object中<br>
5.2. sleep不释放锁，和Object无关</li>
</ol>
<h2 id="why-we-can-t-just-invoke-run-method">Why we can’t just invoke <code>run()</code> method</h2>
<p>Invoke <code>start()</code> will start a new thread and its state will be new.<br>
Then the thread will execute <code>run()</code> automatically after allocated time slice, which is correct usage of thread.<br>
Invoke <code>run()</code> directly means it is invoked in the main thread rather than a new thread, which is not regarded as thread</p>
<h2 id="synchronized">synchronized</h2>
<ol>
<li>Synchronized methods enables a simple strategy for preventing the thread interference and memory consistency errors</li>
<li>Methods or code blocks declared as <code>synchronized</code> can only be visited by one thread at any time</li>
<li><strong>Declaration</strong>
<ol>
<li>instance methods: object lock</li>
<li>static methods: class lock</li>
<li>code block: object lock, it is recommended to use if there are many other codes after synchronized code blocks that are not relevant to concurrency</li>
</ol>
</li>
<li>synchronized vs ReentrantLock
<ol>
<li>Both are reentrant locks: one thread obtain a object lock and this lock can be obtained again by this thread to avoid deadlock</li>
<li>synchronized depends on JVM, ReentrantLock depends on API</li>
<li>ReentrantLock has more advanced features: register waited threads in <code>Condition</code>, then when notifyingAll, it will only notify these registered</li>
</ol>
</li>
</ol>
<h2 id="volatile">volatile</h2>
<p><a href="https://www.cnblogs.com/paddix/p/5428507.html">volatile使用及原理</a><br>
Every threads has their own work memory, so variables are writen in work memory first then written to main memory,<br>
which causes memory consistency errors. <code>volatile</code> let variables read and write directly from main memory.</p>
<ol>
<li>vs synchronized
<ol>
<li>volatile is more efficient than synchronized but it can only declare variable</li>
<li>volatile won’t result in threads blocks, but synchronized will</li>
<li>volatile can guarantee data visibility but atomicity. Sync can guarantee both of them</li>
<li>volatile is used to deal with data visibility, sync is used to deal with resources access from multiple threads</li>
</ol>
</li>
<li>指令重排<br>
实例化一个对象其实可以分为三个步骤: 分配内存空间，初始化对象，将内存空间的地址赋值给对应的引用<br>
但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程：分配内存空间，将内存空间的地址赋值给对应的引用，初始化对象<br>
如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。<br>
因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。</li>
<li>无法保证原子性：e.g. i++</li>
<li>原理：<br>
4.1. 可见性实现：<br>
4.1.1. 修改volatile变量会强制刷新至主内存<br>
4.1.2. 修改volatile变量会导致其他线程工作内存中对应的变量失效，因此需要重新去主内存中读<br>
4.2. 有序性实现(Happen-before)：JMM(Java Memory Model)会对volatile变量限制’编译器重排序’和’处理器重排序’<br>
以上都是通过&quot;内存屏障&quot;实现</li>
</ol>
<h2 id="threadlocal">ThreadLocal</h2>
<ol>
<li>get map from current thread</li>
<li>the key of this map is <code>ThreadLocal&lt;T&gt;</code>, hence one ThreadLocal only store one value</li>
<li>it should be declared as <code>static</code></li>
<li>better to invoke <code>remove()</code> if ThreadLocal is useless since key(ThreadLocal<T>) is weak reference and it may be recycled by jvm,<br>
but its value will not be recycled</T></li>
</ol>
<h2 id="线程池参数">线程池参数</h2>
<ol>
<li>corePoolSize: 核心线程数</li>
<li>maximumPoolSize: 最大线程数</li>
<li>keepAliveTime: 空闲回收时间</li>
<li>unit: 回收时间单位</li>
<li>workQueue: 用于缓存任务的阻塞队列<br>
5.1. 如果没有空闲的线程执行该任务且 当前运行的线程数少于corePoolSize，则添加新的线程执行该任务。<br>
5.2. 如果没有空闲的线程执行该任务且 当前的线程数等于corePoolSize同时阻塞队列未满，则将任务入队列，而不添加新的线程。<br>
5.3. 如果没有空闲的线程执行该任务且 阻塞队列已满同时池中的线程数小于maximumPoolSize，则创建新的线程执行任务。<br>
5.4. 如果没有空闲的线程执行该任务且 阻塞队列已满同时池中的线程数等于maximumPoolSize，则根据构造函数中的handler指定的策略来拒绝新的任务。<br>
5.5. 当一个线程无事可做超过keepAliveTime时,线程池会判断:如果当前运行的线程数大于corePoolSize,那么这个线程就被停掉。<br>
所以线程池的所有任务完成后它最终会收缩到corePoolSize的大小。</li>
<li>threadFactory: 线程工厂，用于创建线程</li>
<li>handler: 拒绝策略<br>
7.1. AbortPolicy: 直接抛出异常<br>
7.2. DiscardPolicy: 直接抛弃任务，无异常<br>
7.3. CallerRunsPolicy: 任务被拒绝添加后，会调用当前线程池的所在线程去执行被拒绝的任务<br>
7.4. DiscardOldestPolicy: 抛弃最老的任务，然后添加这个任务</li>
</ol>
<h3 id="原理">原理</h3>
<ol>
<li>当队列空时，获取元素的线程会等待队列变为非空</li>
<li>当队列满时，存储元素的线程会等待队列可用</li>
</ol>
<h2 id="atomic">Atomic</h2>
<p>use CAS(compare and swap)(optimistic lock) + volatile + native methods to guarantee atomicity rather than synchronized<br>
compareAndSwap(Object object, long offset, int expected, int new) compare offset and expected, if equivalent, write new in memory<br>
if not, do nothing.</p>
<h2 id="aba问题"><strong>ABA</strong>问题</h2>
<p><a href="https://www.jianshu.com/p/71954ea28dd6">ABA problem</a></p>
<hr>
<h1>Lock</h1>
<h2 id="锁分类">锁分类</h2>
<p><a href="https://tech.meituan.com/2018/11/15/java-lock.html">锁分类</a></p>
<ol>
<li>乐观/悲观锁：是否锁住资源</li>
<li>自旋/适应性自旋锁：锁住资源失败，是否阻塞（挂起）</li>
<li>公平/非公平锁：排队/插队（插队失败再排队）</li>
<li>可重入/不可重入锁：一个线程的多个流程是否能获取同一把锁</li>
<li>共享/排他锁：多个线程能否共享一把锁</li>
<li>无锁/偏向锁/轻量级锁/重量级锁（锁状态只能升级不能降级）</li>
</ol>
<h3 id="锁升级">锁升级</h3>
<ol>
<li>无锁：无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功</li>
<li>偏向锁：一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价</li>
<li>轻量级锁：当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能</li>
<li>重量级锁：当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁</li>
</ol>
<h2 id="aqs-abstractqueuedsynchronizer">AQS(AbstractQueuedSynchronizer)</h2>
<p><a href="https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html">从ReentrantLock的实现看AQS的原理及应用</a></p>
<ol>
<li>核心思想：如果被请求的共享资源空闲，将当前线程置为有效的工作线程，将共享资源设置为锁定状态；<br>
如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。<br>
这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。</li>
<li>CLH：Craig、Landin and Hagersten队列，是单向链表<br>
AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。<br>
2.1. 最基本的数据结构：Node<br>
2.1.1. waitStatus: 0(初始化的默认值), 1(cancelled),-2(condition线程等待唤醒),-3(propagate),-1(signal线程就绪，等待资源)<br>
2.1.2. thread<br>
2.1.3. prev: 前驱指针<br>
2.1.4. next: 后继指针<br>
2.1.5. nextWaiter: 指向下一个处于condition状态的节点</li>
<li>两种锁模式:<br>
3.1. exclusive: only one thread can execute, which can be split into two locks<br>
3.1.1. fair lock: get locks according to the order in the queue<br>
3.1.2. unfair lock: resources belong to the thread that grab it first<br>
3.2. share: multiple threads can execute</li>
<li>Based on template model, when customizing, override following methods
<ol>
<li><code>isHeldExclusively()</code></li>
<li><code>tryAcquire(int)</code></li>
<li><code>tryRelease(int)</code></li>
<li><code>tryAcquireShared(int)</code></li>
<li><code>tryReleaseShared(int)</code></li>
</ol>
</li>
<li>Lock(): 非公平锁会先尝试CAS修改state，不行再<code>acquire(1)</code>，公平锁直接<code>acquire(1)</code></li>
</ol>
<h2 id="lock-vs-synchronized">Lock VS Synchronized</h2>
<table>
<thead>
<tr>
<th>类别</th>
<th>synchronized</th>
<th>Lock</th>
</tr>
</thead>
<tbody>
<tr>
<td>存在层次</td>
<td>Java的关键字，在jvm层面上</td>
<td>是一个类</td>
</tr>
<tr>
<td>锁的释放</td>
<td>1、以获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁</td>
<td>在finally中必须释放锁，不然容易造成线程死锁</td>
</tr>
<tr>
<td>锁的获取</td>
<td>假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待</td>
<td>分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待</td>
</tr>
<tr>
<td>锁状态</td>
<td>无法判断</td>
<td>可以判断</td>
</tr>
<tr>
<td>锁类型</td>
<td>可重入 不可中断 非公平</td>
<td>可重入 可判断 可公平（两者皆可）</td>
</tr>
<tr>
<td>性能</td>
<td>少量同步</td>
<td>大量同步</td>
</tr>
</tbody>
</table>
<h2 id="optimization">Optimization</h2>
<ol>
<li>适应性自旋（Adaptive Spinning）: 指定自旋的次数，例如让其循环10次，如果还没获取到锁就进入阻塞状态。<br>
JDK采用了更聪明的方式——适应性自旋，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。</li>
<li>锁粗化（Lock Coarsening）: 将多次连接在一起的加锁、解锁操作合并为一次，将多个连续的锁扩展成一个范围更大的锁。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class StringBufferTest &#123;</span><br><span class="line"> 4     StringBuffer stringBuffer &#x3D; new StringBuffer();</span><br><span class="line"> 5 </span><br><span class="line"> 6     public void append()&#123;</span><br><span class="line"> 7         stringBuffer.append(&quot;a&quot;);</span><br><span class="line"> 8         stringBuffer.append(&quot;b&quot;);</span><br><span class="line"> 9         stringBuffer.append(&quot;c&quot;);</span><br><span class="line">10     &#125;</span><br><span class="line">11 &#125;</span><br></pre></td></tr></table></figure>
<p>如果虚拟机检测到有一系列连串的对同一个对象加锁和解锁操作，就会将其合并成一次范围更大的加锁和解锁操作，<br>
即在第一次append方法时进行加锁，最后一次append方法结束后进行解锁。<br>
3. 锁消除（Lock Elimination）: 根据代码逃逸技术，如果判断到一段代码中，堆上的数据不会逃逸出当前线程，那么可以认为这段代码是线程安全的，不必要加锁。</p>
<hr>
<h1>JVM</h1>
<h2 id="判断对象是否死亡">判断对象是否死亡</h2>
<ol>
<li>引用计数法: 引用计数器加1，引用失效计数器减1;无法解决相互引用的问题</li>
<li>可达性算法: 从GC root出发，没有被遍历到的都可以删了<br>
2.1. 虚拟机栈中引用的对象；方法区中的类静态属性引用的对象；方法区中常量引用的对象；本地方法栈中JNI引用的对象</li>
<li>在被真正回收前要经历两次标记过程2
<ol>
<li>可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize方法。<br>
当对象没有覆盖finalize方法，或finalize方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。</li>
<li>被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。</li>
</ol>
</li>
</ol>
<h2 id="判断一个类是无用的类">判断一个类是无用的类</h2>
<ol>
<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例</li>
<li>加载该类的 ClassLoader 已经被回收</li>
<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法</li>
</ol>
<h2 id="引用">引用</h2>
<ol>
<li>强引用: Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题</li>
<li>软引用: 如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存</li>
<li>弱引用: 一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存</li>
<li>虚引用: 它和没有任何引用一样，在任何时候都可能被垃圾回收</li>
</ol>
<h2 id="垃圾收集算法">垃圾收集算法</h2>
<ol>
<li>标记-清除算法：
<ol>
<li>标记所有需要回收的对象，在标记完成后统一回收</li>
<li>会导致大量不连续的碎片</li>
</ol>
</li>
<li>复制算法
<ol>
<li>将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉</li>
<li>heap使用量是整个的一半</li>
</ol>
</li>
<li>标记-整理算法
<ol>
<li>标记过程与“标记-清除”算法一样，但后续步骤不是直接回收可回收对象，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存</li>
</ol>
</li>
<li>分代收集算法
<ol>
<li>根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法;</li>
<li>新生代每次收集都会有大量对象死去，所以可以选择复制算法(所以才有s1 s0)，只需要付出少量对象的复制成本就可以完成每次垃圾收集;</li>
<li>老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。</li>
<li>相关问题：HotSpot为什么要分为新生代和老年代</li>
</ol>
</li>
</ol>
<h2 id="垃圾收集器">垃圾收集器</h2>
<ol>
<li>Serial:
<ol>
<li>新生代采用复制算法，老年代采用标记-整理算法</li>
<li>单线程，进行垃圾收集工作的时候必须暂停其他所有的工作线程</li>
</ol>
</li>
<li>ParNew
<ol>
<li>Serial收集器的多线程版本</li>
</ol>
</li>
<li>Parallel Scavenge
<ol>
<li>新生代采用复制算法，老年代采用标记-整理算法</li>
<li>多线程，进行垃圾收集工作的时候必须暂停其他所有的工作线程</li>
</ol>
</li>
<li>CMS
<ol>
<li>是一种以获取最短回收停顿时间为目标的收集器</li>
<li>第一次实现了让垃圾收集线程与用户线程同时工作</li>
<li>标记清除</li>
</ol>
</li>
<li>G1
<ol>
<li>可预测的停顿</li>
<li>初始标记, 并发标记, 最终标记, 筛选回收</li>
<li>G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)</li>
</ol>
</li>
</ol>
<p><img src="https://i.stack.imgur.com/4ySVX.png" alt="Clear "></p>
<h2 id="vm-stack-run-time-stack">VM stack(Run-Time Stack)</h2>
<p>栈默认大小：1MB<br>
Each Entry in the stack is called Stack Frame(栈帧)</p>
<p>Stack Frame consists of:</p>
<ol>
<li>LVA(Local Variable Array)(局部变量表): primitive types and object reference</li>
<li>Operand Stack(操作数栈):
<ol>
<li>for storing intermediate calculation’s result</li>
<li>push/pop instructions</li>
</ol>
</li>
<li>Frame Data(FD):
<ol>
<li>contains all symbolic reference and normal method return(方法返回地址)</li>
<li>contains a reference to Exception table which provide the corresponding catch block information in the case of exceptions.</li>
<li>Dynamic Link</li>
</ol>
</li>
</ol>
<p>Invoking a function will push a Stack Frame into VM stack.<br>
When a function finished with return or exception, VM stack will pop this stack frame</p>
<h2 id="native-method-stack">Native Method Stack</h2>
<p>When Native methods are invoked, stack frame will be pushed into Native Method Stack, which is the same as that in VM stack</p>
<h2 id="heap">Heap</h2>
<ol>
<li>
<p>Young Generation(minor GC)</p>
<ol>
<li>eden space: 对象优先在这里分配</li>
<li>s0</li>
<li>s1</li>
</ol>
</li>
<li>
<p>Tenured(old) Generation(full GC)</p>
</li>
<li>
<p>发生Minor GC时: Eden和s0有用对象移至s1(如果年龄够大则到tenured);之后发生Minor GC，Eden和s1有用对象移至s0;s1和s0相互移动</p>
</li>
<li>
<p>当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC. GC期间虚拟机又发现allocation1无法存入Survivor空间，所以只好通过’分配担保机制’把新生代的对象提前转移到老年代中去</p>
</li>
<li>
<p>如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需达到要求的年龄</p>
</li>
</ol>
<h2 id="method-area">Method Area</h2>
<ol>
<li>Contains class info, constants, static variables, etc</li>
<li><strong>Constant Pool</strong> is in this area
<ol>
<li>string pool</li>
<li>primitive pool</li>
<li>JDK1.7 及之后版本的JVM已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。</li>
</ol>
</li>
</ol>
<h2 id="locate-object">locate object</h2>
<ol>
<li>使用句柄<br>
<img src="https://camo.githubusercontent.com/04c82b46121149c8cc9c3b81e18967a5ce06353f/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f2545352541462542392545382542312541312545372539412538342545382541452542462545392539372541452545352541452539412545342542442538442d2545342542442542462545372539342541382545352538462541352545362539462538342e706e67" alt="通过句柄访问"></li>
<li>直接指针<br>
<img src="https://camo.githubusercontent.com/0ae309b058b45ee14004cd001e334355231b2246/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f2545352541462542392545382542312541312545372539412538342545382541452542462545392539372541452545352541452539412545342542442538442d2545372539422542342545362538452541352545362538432538372545392539322538382e706e67" alt="直接指针"><br>
这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，<br>
而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。</li>
</ol>
<h2 id="jvm内存泄漏">JVM内存泄漏</h2>
<p>现象</p>
<ol>
<li>对象已经没有被应用程序使用，但是垃圾回收器没办法移除它们，因为还在被引用着（对象可达，但是对象无用，比如如下容器的例子）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Vector v &#x3D; new Vector(10);</span><br><span class="line"></span><br><span class="line">for (int i &#x3D; 0; i &lt; 100; i++) &#123;</span><br><span class="line">    Object o &#x3D; new Object();</span><br><span class="line">    v.add(o);</span><br><span class="line">    o &#x3D; null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，我们循环申请Object对象，并将所申请的对象放入一个 Vector 中，如果我们仅仅释放引用本身，那么 Vector 仍然引用该对象，<br>
所以这个对象对 GC 来说是不可回收的。因此，如果对象加入到Vector 后，还必须从 Vector 中删除，最简单的方法就是将 Vector 对象设置为 null。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">v &#x3D; null</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>如果长生命周期的对象（单例模式中的对象）持有短生命周期的引用，就很可能会出现内存泄露</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class Simple &#123;</span><br><span class="line"> </span><br><span class="line">    Object object;</span><br><span class="line"> </span><br><span class="line">    public void method1()&#123;</span><br><span class="line">        object &#x3D; new Object();</span><br><span class="line">        &#x2F;&#x2F;...其他代码</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>当method1()方法执行完成后，object对象所分配的内存不会马上被认为是可以被释放的对象，只有在Simple类创建的对象被释放后才会被释放，<br>
严格的说，这就是一种内存泄露。需要在method1最后添加</p>
<h2 id="code-4"><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">object &#x3D; null;</span><br></pre></td></tr></table></figure></h2>
<h1>NIO</h1>
<p><a href="http://tutorials.jenkov.com/java-nio/index.html">Java NIO</a><br>
<a href="https://www.jianshu.com/p/a9b2fec31fd1">Java NIO</a><br>
NIO采用内存映射文件的方式来处理输入输出，NIO将文件或文件的一段区域映射到内存中。</p>
<p>NIO面向通道和缓冲区，不阻塞（异步），当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情<br>
IO面向流，是阻塞的</p>
<h2 id="channel">Channel</h2>
<p>1.双向的<br>
2. FileChannel: reads data from and to files<br>
3. DatagramChannel: read and write data over the network via UDP<br>
4. SocketChannel: read and write data over the network via TCP<br>
5. ServerSocketChannel: allows you to listen for incoming TCP connections, like a web server does.<br>
For each incoming connection a SocketChannel is created.<br>
6. <code>channel.read(buffer)</code> Reads a sequence of bytes from this channel into the given buffer.<br>
7. <code>channel.write(buffer)</code> Writes a sequence of bytes to this channel from the given buffer.</p>
<h2 id="buffer">Buffer</h2>
<p>Main conception:</p>
<ol>
<li>Capacity</li>
<li>Position: MAX(Position)=Capacity-1</li>
<li>Limit
<ol>
<li>In write mode: how much data you can write into the buffer(equal to capacity)</li>
<li>In read mode: how much data you can read from the buffer(when flipping a Buffer into read mode, limit is set to the position)</li>
</ol>
</li>
<li>mark</li>
</ol>
<h2 id="selector">Selector</h2>
<p>Examine one or more channels and determine which channels are ready for reading and writing.<br>
Hence, one threads can handle multiple channels(不必为每个连接创建线程)</p>
<ol>
<li><code>Selector selector = Selector.open();</code> Open a selector</li>
<li>Set channel to non-blocking mode(FileChannel has no such mode)</li>
<li><code>SelectionKey key = channel.register(selector, SelectionKey.OP_READ);</code> to register<br>
(There are four interest sets: Connect, Accept, Read, Write)</li>
</ol>
<h3 id="selectionkey">SelectionKey</h3>
<ol>
<li>Interest set: the set of events that channel is interested in</li>
<li>Ready Set: the set of operations that channel is interested in</li>
</ol>
<h2 id="common-methods">Common Methods</h2>
<ol>
<li>flip(): set limit to position and position to 0 before channel writing</li>
<li>rewind(): set position to 0 before channel rewriting</li>
<li>clear(): set position to 0 and limit to capacity before channel reading</li>
<li>compact(): copy all unread data to the left, set position to (limit - position) and limit to capacity for writing</li>
<li>mark() &amp; reset(): set mark to position and set position to mark</li>
<li>equals()
<ol>
<li>check if they are the same object</li>
<li>check if they are of the same type</li>
<li>check if both (limit - position) are the same</li>
<li>check if elements from (limit - position) to limit are identical</li>
</ol>
</li>
<li>compareTo(): check if elements(start from their own position to Min(limit)) are identical</li>
</ol>
<h2 id="scatter-gather">Scatter / Gather</h2>
<p>The channel “scatters” the data from the channel into multiple buffers. (no working with dynamically sized messages)<br>
The channel “gathers” the data from multiple buffers into one channel. (work with dynamically sized messages)</p>
<h2 id="channel-to-channel-transfer">Channel to Channel Transfer</h2>
<p>Transfer data directly from one channel to another(ByteBuffer Usage is Encapsulated)</p>
<ol>
<li><code>toChannel.transferFrom(fromChannel, position, count);</code></li>
<li><code>fromChannel.transferTo(position, count, toChannel);</code></li>
</ol>
<h2 id="pipe">Pipe</h2>
<p>A pipe has a source channel and a sink channel. Write to sink channel from Thread A and read from source channel from<br>
Thread B.</p>
<h2 id="nio-vs-io">NIO vs IO</h2>
<ol>
<li>IO is Stream Oriented, NIO is Buffer Oriented. For streams
<ol>
<li>No cache</li>
<li>cannot move forth or back in a stream</li>
</ol>
</li>
<li>IO is Blocking, NIO is Non-blocking IO<br><br>
When a thread invokes <code>read()</code> or <code>write()</code> from Java’IO. The thread is blocked.<br>
In Non-blocking mode in NIO, the thread can do something else when handling with channels(can handle multiple channels with selectors).</li>
<li>IO can read in line, which is convenient. NIO read in buffer, which is hard to control if we want to read in line</li>
<li>use NIO if there are thousands of open connections simultaneously, which each only send a little data such as chat<br>
system.</li>
<li>use IO if there are few connections with very high bandwidth.</li>
</ol>
<hr>
<h1>ClassLoad</h1>
<h2 id="类加载器">类加载器</h2>
<ol>
<li>BootstrapClassLoader(启动类加载器): 最顶层的加载类，由C++实现，负责加载%JAVA_HOME%/lib目录下的jar包和类或者或被 -Xbootclasspath参数指定的路径中的所有类</li>
<li>ExtensionClassLoader(扩展类加载器): 主要负责加载目录 %JRE_HOME%/lib/ext 目录下的jar包和类，或被 java.ext.dirs 系统变量所指定的路径下的jar包</li>
<li>AppClassLoader(应用程序类加载器): 面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类</li>
<li>AppClassLoader的父类加载器为ExtClassLoader ExtClassLoader的父类加载器为null，null并不代表ExtClassLoader没有父类加载器，而是BootstrapClassLoader</li>
</ol>
<h2 id="双亲委派模型">双亲委派模型</h2>
<ol>
<li>The Java platform uses a delegation model for loading classes.<br>
The basic idea is that every class loader has a “parent” class loader.<br>
When loading a class, a class loader first “delegates” the search for the<br>
class to its parent class loader before attempting to find the class itself.</li>
<li><img src="https://camo.githubusercontent.com/4311721b0968c1b9fd63bdc0acf11d7358a52ff6/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f636c6173736c6f616465725f5750532545352539422542452545372538392538372e706e67" alt="img info"></li>
<li>避免类的重复加载</li>
<li>除了BootstrapClassLoader, 其他类加载器均由Java实现且全部继承自java.lang.ClassLoader</li>
</ol>
<hr>
<h1>Error and Exception</h1>
<ol>
<li>都继承于throwable</li>
<li>Error: 一般指与虚拟机相关的问题：系统崩溃，JVM错误，内存不足。仅靠程序本身无法恢复，建议让程序终止</li>
<li>Exception: 表示程序可以捕获并处理的异常<br>
3.1. Runtime/Unchecked Exception: 在编译时可被忽略<br>
3.1.1. NullPointerException<br>
3.1.2. ClassCastException<br>
3.1.3. ArrayIndexOutOfBoundsException<br>
3.2. Checked Exception: 在编译时不可被忽略，使用try-catch或者throws子句抛出<br>
3.2.1. IOException<br>
3.2.1. SQLException<br>
3.2.1. 用户自定义的</li>
</ol>
<hr>
<h1>Spring</h1>
<h2 id="七个事务传播属性">七个事务传播属性</h2>
<ol>
<li>Required: 支持当前事务，如果当前没有事务，就新建一个事务</li>
<li>Supports: 支持当前事务，如果当前没有事务，就以非事务方式执行</li>
<li>Mandatory: 支持当前事务，如果当前没有事务，就抛出异常</li>
<li>Requires new: 新建事务，如果当前存在事务，把当前事务挂起</li>
<li>Not support: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起</li>
<li>Never: 以非事务方式执行，如果当前存在事务，则抛出异常</li>
<li>Nested: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与REQUIRED类似的操作</li>
</ol>
<h2 id="五个隔离级别">五个隔离级别</h2>
<ol>
<li>ISOLATION_DEFAULT: 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别</li>
<li>ISOLATION_READ_UNCOMMITTED</li>
<li>ISOLATION_READ_COMMITTED</li>
<li>ISOLATION_REPEATABLE_READ</li>
<li>ISOLATION_SERIALIZABLE</li>
</ol>
<h2 id="spring-aop">Spring AOP</h2>
<p>通过代理在运行时织入<br>
<a href="https://www.cnblogs.com/swordfall/p/12880809.html">Spring代理</a></p>
<ol>
<li>静态代理</li>
<li>动态代理<br>
2.1. 基于接口的代理(JDK代理)：<br>
2.1.1. 基于reflect.proxy类<br>
2.1.2. 代理类要实现InvocationHandler接口<br>
2.1.3. 需要接口进行动态代理<br>
2.2. 基于继承的代理(CGlib代理)<br>
2.2.1. CGLib采用非常底层的字节码技术，可以为一个类创建子类，并在子类中采用方法去技术拦截所有的父类方法的调用，并顺势织入横切逻辑<br>
2.2.2. CGLib和JDK的原理类似，也是通过方法去反射调用目标对象的方法</li>
</ol>
<h2 id="spring-mvc">Spring MVC</h2>
<ol>
<li>客户端发送请求到DispatcherServlet</li>
<li>调用HandlerMapping解析对应的Handler</li>
<li>解析到对应的Handler,交给HandlerAdapter处理</li>
<li>HandlerAdapter根据Handler调用Controller处理业务</li>
<li>Controller处理完后会返回一个ModelAndView对象，Model是返回的数据对象，View是逻辑上的View</li>
<li>ViewResolver根据View查找实际的View</li>
<li>DispatcherServlet把model传给view（视图渲染）</li>
<li>把View返回给客户端</li>
</ol>
<h2 id="bean作用域以及部分生命周期">Bean作用域以及部分生命周期</h2>
<ol>
<li>Singleton: Spring IoC容器中只会存在一个共享的bean实例(可以实行lazy init)<br>
Spring容器可以管理singleton作用域下bean的生命周期:何时被创建，何时初始化完成，以及何时被销毁</li>
<li>Prototype: 每次请求都会创建一个新的bean实例<br>
Spring只负责创建，当容器创建了bean的实例后，bean的实例就交给了客户端的代码管理</li>
<li>Request:   每次Http请求会产生一个新的bean，该bean仅在当前HTTPRequest内有效</li>
<li>Session:   每一次HTTP请求都会产生一个新的 bean，该bean仅在当前HTTPSession内有效</li>
<li>GlobalSession:</li>
</ol>
<h2 id="bean生命周期">Bean生命周期</h2>
<hr>
<h1>三大特性</h1>
<p>封装，继承，多态</p>
<hr>
<h1>Primitives</h1>
<p>byte:     8 bits<br>
short:   16 bits<br>
char:    16 bits<br>
int:     32 bits<br>
float:    32 bits<br>
double:  64 bits<br>
long:    64 bits<br>
boolean: boolean在数组情况下为1个字节，单个boolean为4个字节<br>
(boolean值在编译后都使用Java虚拟机中的int数据类型来代替，而int是4字节，那么boolean值就是4字节;<br>
boolean类型数组的访问与修改共用byte类型数组的baload和 bastore指令，所以byte数组中一个byte是1个字节，那么boolean数组中boolean是1个字节)</p>
<hr>
<h1>Others</h1>
<h2 id="string-s-new-string-xyz-创建了几个对象">String s = new String(“xyz”); 创建了几个对象</h2>
<ol>
<li>在运行时常量池的string pool里面寻找是否存在&quot;xyz&quot;，若不存在，则创建这个string对象</li>
<li>通过new String(“xyz”)创建并初始化内容与&quot;xyz&quot;相同的实例</li>
</ol>
<h2 id="oom问题查找">OOM问题查找</h2>
<p><a href="https://blog.csdn.net/jjavaboy/article/details/77773754">OOM问题排查</a></p>
<ol>
<li>内存分配过小，通过<code>jmap -heap PID</code>查看heap使用情况</li>
<li>找到最耗内存的对象（实例数，所占内存，类名）(可能存在未释放内存的情况 或者 消费者消费速度慢（或停止消费了），而生产者不断往队列中投递任务，导致队列中任务累积过多）</li>
<li>确认资源是否耗尽<br>
3.1. <code>pstree</code>, <code>netstat</code><br>
3.2. <code>ll /proc/$&#123;PID&#125;/fd</code><a href="https://unix.stackexchange.com/questions/10050/proc-pid-fd-x-link-number">fd内容意义</a>,<code>ll /proc/$&#123;PID&#125;/task</code>(查看线程)</li>
</ol>
<h2 id="拆箱-装箱例子">拆箱，装箱例子</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Integer i1 &#x3D; 40;</span><br><span class="line">Integer i2 &#x3D; 40;</span><br><span class="line">Integer i3 &#x3D; 0;</span><br><span class="line">Integer i4 &#x3D; new Integer(40);</span><br><span class="line">Integer i5 &#x3D; new Integer(40);</span><br><span class="line">Integer i6 &#x3D; new Integer(0);</span><br><span class="line"></span><br><span class="line">System.out.println(&quot;i1&#x3D;i2   &quot; + (i1 &#x3D;&#x3D; i2));</span><br><span class="line">System.out.println(&quot;i1&#x3D;i2+i3   &quot; + (i1 &#x3D;&#x3D; i2 + i3));</span><br><span class="line">System.out.println(&quot;i1&#x3D;i4   &quot; + (i1 &#x3D;&#x3D; i4));</span><br><span class="line">System.out.println(&quot;i4&#x3D;i5   &quot; + (i4 &#x3D;&#x3D; i5));</span><br><span class="line">System.out.println(&quot;i4&#x3D;i5+i6   &quot; + (i4 &#x3D;&#x3D; i5 + i6));   </span><br><span class="line">System.out.println(&quot;40&#x3D;i5+i6   &quot; + (40 &#x3D;&#x3D; i5 + i6));</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">i1&#x3D;i2   true</span><br><span class="line">i1&#x3D;i2+i3   true</span><br><span class="line">i1&#x3D;i4   false</span><br><span class="line">i4&#x3D;i5   false</span><br><span class="line">i4&#x3D;i5+i6   true</span><br><span class="line">40&#x3D;i5+i6   true</span><br></pre></td></tr></table></figure>
<p>Explanation: <br><br>
语句 i4 == i5 + i6，因为+这个操作符不适用于 Integer 对象，首先 i5 和 i6 进行自动拆箱操作，进行数值相加，即 i4 == 40。<br>
然后 Integer 对象无法与数值进行直接比较，所以 i4 自动拆箱转为 int 值 40，最终这条语句转为 40 == 40 进行数值比较。</p>
<hr>
]]></content>
      <categories>
        <category>Interview</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Thread</tag>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Lock</tag>
        <tag>JVM</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
</search>
